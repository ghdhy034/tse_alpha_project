# models/data_loader.py
"""
TSE Alpha è³‡æ–™è¼‰å…¥å™¨ - èˆ‡ç‰¹å¾µå·¥ç¨‹å’Œ Gym ç’°å¢ƒç›¸å®¹
"""
from __future__ import annotations
import sys
import os
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any, Iterator
from dataclasses import dataclass
from datetime import datetime, date
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
import logging

# æ·»åŠ è·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent))
sys.path.append(str(Path(__file__).parent.parent / "data_pipeline"))
sys.path.append(str(Path(__file__).parent.parent / "market_data_collector"))

try:
    from data_pipeline.features import FeatureEngine
    from market_data_collector.utils.db import query_df
    from market_data_collector.utils.config import STOCK_IDS
except ImportError as e:
    print(f"è­¦å‘Š: ç„¡æ³•å°å…¥æ¨¡çµ„: {e}")
    STOCK_IDS = ['2330', '2317', '2603']

logger = logging.getLogger(__name__)


@dataclass
class DataConfig:
    """è³‡æ–™é…ç½®"""
    # è³‡æ–™ç¯„åœ
    symbols: List[str] = None
    train_start_date: str = '2020-03-02'
    train_end_date: str = '2023-12-31'
    val_start_date: str = '2024-01-01'
    val_end_date: str = '2024-06-30'
    test_start_date: str = '2024-07-01'
    test_end_date: str = '2024-12-31'
    
    # åºåˆ—åƒæ•¸
    sequence_length: int = 64
    prediction_horizon: int = 5
    
    # æ‰¹æ¬¡åƒæ•¸
    batch_size: int = 32
    num_workers: int = 4
    
    # ç‰¹å¾µåƒæ•¸
    normalize_features: bool = True
    include_chip_features: bool = True
    
    # æ¨™ç±¤é¡å‹
    label_type: str = 'regression'  # 'regression', 'classification', 'ranking'
    
    def __post_init__(self):
        if self.symbols is None:
            self.symbols = STOCK_IDS[:20]  # é è¨­ä½¿ç”¨å‰20æª”è‚¡ç¥¨


class TSEDataset(Dataset):
    """TSE Alpha è³‡æ–™é›† - èˆ‡ Gym ç’°å¢ƒè§€æ¸¬æ ¼å¼ç›¸å®¹"""
    
    def __init__(self, 
                 features_dict: Dict[str, Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]],
                 config: DataConfig,
                 mode: str = 'train'):
        """
        Args:
            features_dict: {symbol: (features, labels, prices)}
            config: è³‡æ–™é…ç½®
            mode: 'train', 'val', 'test'
        """
        self.features_dict = features_dict
        self.config = config
        self.mode = mode
        self.symbols = list(features_dict.keys())
        
        # å»ºç«‹åºåˆ—ç´¢å¼•
        self.sequence_indices = self._build_sequence_indices()
        
        logger.info(f"{mode} è³‡æ–™é›†: {len(self.sequence_indices)} å€‹åºåˆ—, {len(self.symbols)} æª”è‚¡ç¥¨")
    
    def _build_sequence_indices(self) -> List[Tuple[str, int]]:
        """å»ºç«‹åºåˆ—ç´¢å¼• (symbol, start_idx)"""
        indices = []
        
        for symbol in self.symbols:
            if symbol not in self.features_dict:
                continue
                
            features, labels, prices = self.features_dict[symbol]
            
            # ç¢ºä¿æœ‰è¶³å¤ çš„è³‡æ–™å»ºç«‹åºåˆ—
            min_length = self.config.sequence_length + self.config.prediction_horizon
            if len(features) < min_length:
                continue
            
            # ç‚ºæ¯å€‹å¯èƒ½çš„èµ·å§‹ä½ç½®å»ºç«‹ç´¢å¼•
            max_start_idx = len(features) - min_length
            for start_idx in range(max_start_idx + 1):
                indices.append((symbol, start_idx))
        
        return indices
    
    def __len__(self) -> int:
        return len(self.sequence_indices)
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """
        ç²å–å–®å€‹æ¨£æœ¬ - æ ¼å¼èˆ‡ Gym ç’°å¢ƒè§€æ¸¬ç›¸å®¹
        
        Returns:
            sample: {
                'observation': {
                    'price_frame': (n_stocks, seq_len, 5),
                    'fundamental': (10,),
                    'account': (4,)
                },
                'labels': (prediction_horizon,),
                'metadata': {...}
            }
        """
        symbol, start_idx = self.sequence_indices[idx]
        features, labels, prices = self.features_dict[symbol]
        
        # æå–åºåˆ—
        end_idx = start_idx + self.config.sequence_length
        label_idx = end_idx + self.config.prediction_horizon - 1
        
        # åƒ¹æ ¼æ¡†æ¶è³‡æ–™ (OHLCV)
        price_sequence = prices.iloc[start_idx:end_idx]
        price_frame = self._extract_price_frame(price_sequence)
        
        # åŸºæœ¬é¢ç‰¹å¾µ (ä½¿ç”¨åºåˆ—æœ€å¾Œä¸€å¤©çš„å€¼)
        feature_row = features.iloc[end_idx - 1]
        fundamental_features = self._extract_fundamental_features(feature_row)
        
        # å¸³æˆ¶ç‹€æ…‹ (æ¨¡æ“¬)
        account_features = self._simulate_account_state(symbol, end_idx)
        
        # æ¨™ç±¤
        if label_idx < len(labels):
            label_row = labels.iloc[label_idx]
            target_labels = self._extract_labels(label_row)
        else:
            target_labels = torch.zeros(1)  # é è¨­æ¨™ç±¤
        
        # æ§‹å»ºè§€æ¸¬ (èˆ‡ Gym ç’°å¢ƒæ ¼å¼ç›¸å®¹)
        observation = {
            'price_frame': price_frame,
            'fundamental': fundamental_features,
            'account': account_features
        }
        
        # å…ƒè³‡æ–™ (ä¿®å¾© Timestamp åºåˆ—åŒ–å•é¡Œ)
        metadata = {
            'symbol': symbol,
            'start_date': str(price_sequence.index[0]),  # è½‰æ›ç‚ºå­—ç¬¦ä¸²
            'end_date': str(price_sequence.index[-1]),   # è½‰æ›ç‚ºå­—ç¬¦ä¸²
            'current_price': float(price_sequence.iloc[-1]['close'])
        }
        
        return {
            'observation': observation,
            'labels': target_labels,
            'metadata': metadata
        }
    
    def _extract_price_frame(self, price_sequence: pd.DataFrame) -> torch.Tensor:
        """æå–åƒ¹æ ¼æ¡†æ¶ - åŸºæ–¼66ç¶­ç‰¹å¾µé…ç½®çš„å…¶ä»–ç‰¹å¾µéƒ¨åˆ†"""
        # ç²å–å¯¦éš›é…ç½®çš„å…¶ä»–ç‰¹å¾µæ•¸é‡ (51å€‹: åƒ¹é‡+æŠ€è¡“+ç±Œç¢¼+ä¼°å€¼+æ—¥å…§çµæ§‹)
        try:
            from models.config.training_config import TrainingConfig
            config = TrainingConfig()
            other_features_count = config.other_features  # 51å€‹å…¶ä»–ç‰¹å¾µ
        except:
            other_features_count = 51  # é è¨­å€¼ (66ç¶­é…ç½®)
        
        # ä½¿ç”¨ç‰¹å¾µå¼•æ“è¨ˆç®—å®Œæ•´çš„å…¶ä»–ç‰¹å¾µ (51å€‹ï¼Œ66ç¶­é…ç½®)
        from data_pipeline.features import FeatureEngine
        feature_engine = FeatureEngine()
        
        # è¨ˆç®—æ‰€æœ‰å…¶ä»–ç‰¹å¾µ (51å€‹: åƒ¹é‡+æŠ€è¡“+ç±Œç¢¼+ä¼°å€¼+æ—¥å…§çµæ§‹ï¼Œ66ç¶­é…ç½®)
        # é€™è£¡éœ€è¦å®Œæ•´çš„ç‰¹å¾µè™•ç†ï¼Œæš«æ™‚ä½¿ç”¨æŠ€è¡“ç‰¹å¾µä½œç‚ºåŸºç¤
        tech_features = feature_engine.calculate_technical_features(price_sequence)
        
        if tech_features.empty or tech_features.shape[1] < 27:
            # å¦‚æœç‰¹å¾µè¨ˆç®—å¤±æ•—ï¼Œä½¿ç”¨é›¶å¡«å……
            other_array = np.zeros((len(price_sequence), other_features_count))
        else:
            # å‰µå»º51å€‹å…¶ä»–ç‰¹å¾µçš„æ•¸çµ„
            other_array = np.zeros((len(price_sequence), other_features_count))
            tech_array = tech_features.to_numpy()  # (seq_len, 27)
            
            # å¡«å……å‰27å€‹ç‰¹å¾µï¼ˆæŠ€è¡“ç‰¹å¾µï¼‰
            other_array[:, :min(27, other_features_count)] = tech_array[:, :min(27, other_features_count)]
            
            # å¡«å……å‰©é¤˜çš„24å€‹ç‰¹å¾µï¼ˆç±Œç¢¼+ä¼°å€¼+æ—¥å…§çµæ§‹+å…¶ä»–ï¼‰
            remaining_features = other_features_count - 27
            if remaining_features > 0 and len(price_sequence) > 0:
                # æ·»åŠ ä¸€äº›åŸºæ–¼åƒ¹æ ¼çš„ç°¡å–®ç‰¹å¾µä½œç‚ºå¡«å……
                close_prices = price_sequence['close'].values
                if len(close_prices) > 1:
                    # è¨ˆç®—åƒ¹æ ¼è®ŠåŒ–ç‡
                    price_returns = np.diff(close_prices) / (close_prices[:-1] + 1e-8)
                    price_returns = np.concatenate([[0], price_returns])  # ç¬¬ä¸€å€‹å€¼è¨­ç‚º0
                    
                    # è¨ˆç®—ç§»å‹•å¹³å‡åå·®
                    if len(close_prices) >= 5:
                        ma5 = np.convolve(close_prices, np.ones(5)/5, mode='same')
                        ma_deviation = (close_prices - ma5) / (ma5 + 1e-8)
                    else:
                        ma_deviation = np.zeros_like(close_prices)
                    
                    # å¡«å……å‰©é¤˜ç‰¹å¾µ
                    for i in range(remaining_features):
                        if i % 2 == 0 and i//2 < len(price_returns):
                            other_array[:, 27 + i] = price_returns[min(i//2, len(price_returns)-1)]
                        elif i % 2 == 1 and i//2 < len(ma_deviation):
                            other_array[:, 27 + i] = ma_deviation[min(i//2, len(ma_deviation)-1)]
        
        # æ“´å±•åˆ°å¤šè‚¡ç¥¨æ ¼å¼ (ç‚ºäº†èˆ‡æ¨¡å‹ç›¸å®¹)
        # ä½¿ç”¨å¯¦éš›çš„symbolsæ•¸é‡è€Œä¸æ˜¯config.symbols
        actual_symbols_count = len(self.symbols) if hasattr(self, 'symbols') else 1
        price_frame = np.zeros((actual_symbols_count, self.config.sequence_length, other_features_count))
        
        # æ‰¾åˆ°ç•¶å‰è‚¡ç¥¨åœ¨ç¬¦è™Ÿåˆ—è¡¨ä¸­çš„ä½ç½®
        symbol_idx = 0  # é è¨­ä½¿ç”¨ç¬¬ä¸€å€‹ä½ç½®
        if hasattr(self, 'symbols') and len(self.symbols) > 0:
            # å¾sequence_indicesä¸­ç²å–ç•¶å‰symbol
            current_symbol = self.sequence_indices[0][0] if self.sequence_indices else self.symbols[0]
            if current_symbol in self.symbols:
                symbol_idx = self.symbols.index(current_symbol)
        
        # å¡«å……ç•¶å‰è‚¡ç¥¨çš„è³‡æ–™ (ç¢ºä¿ç´¢å¼•å®‰å…¨)
        seq_len = min(len(other_array), self.config.sequence_length)
        if symbol_idx < price_frame.shape[0]:  # å®‰å…¨æª¢æŸ¥
            price_frame[symbol_idx, -seq_len:, :] = other_array[-seq_len:]
        
        return torch.tensor(price_frame, dtype=torch.float32)
    
    def _extract_fundamental_features(self, feature_row: pd.Series) -> torch.Tensor:
        """æå–åŸºæœ¬é¢ç‰¹å¾µ"""
        # ç²å–å¯¦éš›é…ç½®çš„åŸºæœ¬é¢ç‰¹å¾µæ•¸é‡ (15å€‹: æœˆç‡Ÿæ”¶+è²¡å ±ï¼Œ66ç¶­é…ç½®)
        try:
            from models.config.training_config import TrainingConfig
            config = TrainingConfig()
            fundamental_dim = config.fundamental_features  # 15å€‹åŸºæœ¬é¢ç‰¹å¾µ (66ç¶­é…ç½®)
        except:
            fundamental_dim = 15  # é è¨­å€¼ (66ç¶­é…ç½®)
        
        # å¾ç‰¹å¾µè¡Œä¸­æå–åŸºæœ¬é¢ç›¸é—œç‰¹å¾µ
        fundamental_cols = [col for col in feature_row.index if 'fundamental' in col or 'market_cap' in col or 'liquidity' in col]
        
        if len(fundamental_cols) >= fundamental_dim:
            fundamental_values = feature_row[fundamental_cols[:fundamental_dim]].values
        else:
            # å¦‚æœåŸºæœ¬é¢ç‰¹å¾µä¸è¶³ï¼Œç”¨å…¶ä»–ç‰¹å¾µè£œå……
            all_values = feature_row.values
            fundamental_values = np.zeros(fundamental_dim)
            fundamental_values[:min(len(all_values), fundamental_dim)] = all_values[:min(len(all_values), fundamental_dim)]
        
        return torch.tensor(fundamental_values, dtype=torch.float32)
    
    def _simulate_account_state(self, symbol: str, current_idx: int) -> torch.Tensor:
        """æ¨¡æ“¬å¸³æˆ¶ç‹€æ…‹"""
        # åœ¨å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œé€™æ‡‰è©²å¾å›æ¸¬ç³»çµ±æˆ–å¯¦éš›å¸³æˆ¶ç‹€æ…‹ç²å–
        # é€™è£¡æä¾›æ¨¡æ“¬å€¼
        
        # NAV è®ŠåŒ– (æ¨™æº–åŒ–)
        nav_change = np.random.normal(0, 0.01)
        
        # æŒå€‰æ¯”ä¾‹
        position_ratio = np.random.uniform(0, 0.8)
        
        # æœªå¯¦ç¾æç›Šç™¾åˆ†æ¯”
        unrealized_pnl = np.random.normal(0, 0.02)
        
        # é¢¨éšªç·©è¡
        risk_buffer = np.random.uniform(0.2, 1.0)
        
        account_state = np.array([nav_change, position_ratio, unrealized_pnl, risk_buffer])
        return torch.tensor(account_state, dtype=torch.float32)
    
    def _extract_labels(self, label_row: pd.Series) -> torch.Tensor:
        """æå–æ¨™ç±¤"""
        if self.config.label_type == 'regression':
            # å›æ­¸æ¨™ç±¤ (æœªä¾†æ”¶ç›Šç‡)
            return_col = f'return_{self.config.prediction_horizon}d'
            if return_col in label_row.index:
                return torch.tensor([label_row[return_col]], dtype=torch.float32)
            else:
                return torch.tensor([0.0], dtype=torch.float32)
        
        elif self.config.label_type == 'classification':
            # åˆ†é¡æ¨™ç±¤ (æ¼²è·Œ)
            up_col = f'up_{self.config.prediction_horizon}d'
            if up_col in label_row.index:
                return torch.tensor([label_row[up_col]], dtype=torch.long)
            else:
                return torch.tensor([0], dtype=torch.long)
        
        elif self.config.label_type == 'ranking':
            # æ’åºæ¨™ç±¤ (ç›¸å°è¡¨ç¾)
            return_col = f'return_{self.config.prediction_horizon}d'
            if return_col in label_row.index:
                return torch.tensor([label_row[return_col]], dtype=torch.float32)
            else:
                return torch.tensor([0.0], dtype=torch.float32)
        
        return torch.tensor([0.0], dtype=torch.float32)


class MultiStockDataset(Dataset):
    """å¤šè‚¡ç¥¨è³‡æ–™é›† - åŒæ™‚è™•ç†å¤šæª”è‚¡ç¥¨"""
    
    def __init__(self,
                 features_dict: Dict[str, Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]],
                 config: DataConfig,
                 mode: str = 'train'):
        self.features_dict = features_dict
        self.config = config
        self.mode = mode
        self.symbols = list(features_dict.keys())[:config.symbols.__len__()]  # é™åˆ¶è‚¡ç¥¨æ•¸é‡
        
        # å°é½Šæ‰€æœ‰è‚¡ç¥¨çš„æ—¥æœŸ
        self.aligned_data = self._align_stock_data()
        self.date_indices = list(range(len(self.aligned_data)))
        
        logger.info(f"{mode} å¤šè‚¡ç¥¨è³‡æ–™é›†: {len(self.date_indices)} å€‹æ™‚é–“é», {len(self.symbols)} æª”è‚¡ç¥¨")
    
    def _align_stock_data(self) -> pd.DataFrame:
        """å°é½Šæ‰€æœ‰è‚¡ç¥¨çš„è³‡æ–™åˆ°ç›¸åŒçš„æ—¥æœŸç´¢å¼•"""
        all_dates = set()
        
        # æ”¶é›†æ‰€æœ‰æ—¥æœŸ
        for symbol in self.symbols:
            if symbol in self.features_dict:
                features, _, _ = self.features_dict[symbol]
                all_dates.update(features.index)
        
        # å‰µå»ºçµ±ä¸€çš„æ—¥æœŸç´¢å¼•
        common_dates = sorted(all_dates)
        return pd.DataFrame(index=common_dates)
    
    def __len__(self) -> int:
        # ä¿®å¾©ï¼šç¢ºä¿æœ‰è¶³å¤ çš„è³‡æ–™é»ä¾†å»ºç«‹åºåˆ—
        available_dates = len(self.date_indices)
        min_required = self.config.sequence_length + self.config.prediction_horizon
        
        if available_dates < min_required:
            print(f"âš ï¸ è³‡æ–™ä¸è¶³: å¯ç”¨æ—¥æœŸ{available_dates}å¤© < æœ€å°‘éœ€è¦{min_required}å¤©")
            return 0
        
        # å¯ç”¨çš„åºåˆ—æ•¸é‡ = ç¸½æ—¥æœŸæ•¸ - åºåˆ—é•·åº¦ - é æ¸¬ç¯„åœ + 1
        sequence_count = available_dates - min_required + 1
        print(f"ğŸ“Š MultiStockDataset: {available_dates}å€‹æ—¥æœŸ â†’ {sequence_count}å€‹åºåˆ—")
        return max(0, sequence_count)
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """
        ç²å–å¤šè‚¡ç¥¨æ¨£æœ¬
        
        Returns:
            sample: {
                'observation': {
                    'price_frame': (n_stocks, seq_len, 5),
                    'fundamental': (10,),
                    'account': (4,)
                },
                'labels': (n_stocks,),
                'metadata': {...}
            }
        """
        start_idx = idx
        end_idx = start_idx + self.config.sequence_length
        label_idx = end_idx + self.config.prediction_horizon - 1
        
        # ç²å–æ—¥æœŸç¯„åœ
        date_range = self.aligned_data.index[start_idx:end_idx]
        target_date = self.aligned_data.index[label_idx] if label_idx < len(self.aligned_data) else None
        
        # ç²å–å¯¦éš›é…ç½®çš„å…¶ä»–ç‰¹å¾µæ•¸é‡ (66ç¶­é…ç½®ä¸­çš„51å€‹å…¶ä»–ç‰¹å¾µ)
        try:
            from models.config.training_config import TrainingConfig
            config = TrainingConfig()
            price_features_count = config.other_features  # 51å€‹å…¶ä»–ç‰¹å¾µ
        except:
            price_features_count = 51  # é è¨­å€¼ (66ç¶­é…ç½®)
        
        # æ§‹å»ºå¤šè‚¡ç¥¨åƒ¹æ ¼æ¡†æ¶ - ä½¿ç”¨51å€‹å…¶ä»–ç‰¹å¾µ
        price_frame = np.zeros((len(self.symbols), self.config.sequence_length, price_features_count))
        
        # ç²å–å¯¦éš›é…ç½®çš„åŸºæœ¬é¢ç‰¹å¾µæ•¸é‡ (15å€‹ï¼Œ66ç¶­é…ç½®)
        try:
            from models.config.training_config import TrainingConfig
            config = TrainingConfig()
            fundamental_dim = config.fundamental_features  # 15å€‹åŸºæœ¬é¢ç‰¹å¾µ (66ç¶­é…ç½®)
        except:
            fundamental_dim = 15  # é è¨­å€¼ (66ç¶­é…ç½®)
        
        fundamental_features = np.zeros(fundamental_dim)
        labels = np.zeros(len(self.symbols))
        
        for i, symbol in enumerate(self.symbols):
            # ç¢ºä¿ç´¢å¼•ä¸è¶…å‡ºprice_frameçš„é‚Šç•Œ
            if i >= len(self.symbols):
                break
                
            if symbol not in self.features_dict:
                continue
            
            features, stock_labels, prices = self.features_dict[symbol]
            
            # æå–è©²è‚¡ç¥¨åœ¨æ—¥æœŸç¯„åœå…§çš„åƒ¹æ ¼è³‡æ–™
            stock_prices = prices.reindex(date_range, method='ffill').dropna()
            
            if len(stock_prices) > 0:
                # ä½¿ç”¨ç‰¹å¾µå¼•æ“è¨ˆç®—å®Œæ•´çš„51å€‹å…¶ä»–ç‰¹å¾µ
                from data_pipeline.features import FeatureEngine
                feature_engine = FeatureEngine()
                
                # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ç‰¹å¾µ (è¿”å›27å€‹ç‰¹å¾µ: 5å€‹OHLCV + 22å€‹æŠ€è¡“æŒ‡æ¨™)
                tech_features = feature_engine.calculate_technical_features(stock_prices)
                
                if not tech_features.empty and tech_features.shape[1] >= 27:
                    # å‰µå»º51å€‹å…¶ä»–ç‰¹å¾µçš„æ•¸çµ„
                    price_data = np.zeros((len(stock_prices), price_features_count))
                    tech_array = tech_features.to_numpy()  # (seq_len, 27)
                    
                    # å¡«å……å‰27å€‹ç‰¹å¾µï¼ˆæŠ€è¡“ç‰¹å¾µï¼‰
                    price_data[:, :min(27, price_features_count)] = tech_array[:, :min(27, price_features_count)]
                    
                    # å¡«å……å‰©é¤˜çš„24å€‹ç‰¹å¾µ
                    remaining_features = price_features_count - 27
                    if remaining_features > 0 and len(stock_prices) > 0:
                        close_prices = stock_prices['close'].values
                        if len(close_prices) > 1:
                            # è¨ˆç®—åƒ¹æ ¼è®ŠåŒ–ç‡
                            price_returns = np.diff(close_prices) / (close_prices[:-1] + 1e-8)
                            price_returns = np.concatenate([[0], price_returns])
                            
                            # è¨ˆç®—ç§»å‹•å¹³å‡åå·®
                            if len(close_prices) >= 5:
                                ma5 = np.convolve(close_prices, np.ones(5)/5, mode='same')
                                ma_deviation = (close_prices - ma5) / (ma5 + 1e-8)
                            else:
                                ma_deviation = np.zeros_like(close_prices)
                            
                            # å¡«å……å‰©é¤˜ç‰¹å¾µ (ä¿®å¾©è®Šæ•¸åè¡çª)
                            for j in range(remaining_features):
                                if j % 2 == 0 and j//2 < len(price_returns):
                                    price_data[:, 27 + j] = price_returns[min(j//2, len(price_returns)-1)]
                                elif j % 2 == 1 and j//2 < len(ma_deviation):
                                    price_data[:, 27 + j] = ma_deviation[min(j//2, len(ma_deviation)-1)]
                else:
                    # å¦‚æœç‰¹å¾µè¨ˆç®—å¤±æ•—ï¼Œä½¿ç”¨é›¶å¡«å……
                    price_data = np.zeros((len(stock_prices), price_features_count))
                
                # å¡«å……åˆ°å›ºå®šé•·åº¦ (ç¢ºä¿ç´¢å¼•å®‰å…¨)
                seq_len = min(len(price_data), self.config.sequence_length)
                if i < price_frame.shape[0]:  # é¡å¤–çš„å®‰å…¨æª¢æŸ¥
                    price_frame[i, -seq_len:, :] = price_data[-seq_len:]
            
            # æå–æ¨™ç±¤
            if target_date and target_date in stock_labels.index:
                label_row = stock_labels.loc[target_date]
                return_col = f'return_{self.config.prediction_horizon}d'
                if return_col in label_row.index:
                    labels[i] = label_row[return_col]
        
        # èšåˆåŸºæœ¬é¢ç‰¹å¾µ (ä½¿ç”¨æ‰€æœ‰è‚¡ç¥¨çš„å¹³å‡)
        for symbol in self.symbols:
            if symbol in self.features_dict and end_idx - 1 < len(self.features_dict[symbol][0]):
                features, _, _ = self.features_dict[symbol]
                if end_idx - 1 < len(features):
                    feature_row = features.iloc[end_idx - 1]
                    fundamental_cols = [col for col in feature_row.index if 'fundamental' in col][:fundamental_dim]
                    if fundamental_cols:
                        fundamental_features[:len(fundamental_cols)] += feature_row[fundamental_cols].values
        
        fundamental_features /= len(self.symbols)  # å¹³å‡åŒ–
        
        # æ¨¡æ“¬å¸³æˆ¶ç‹€æ…‹
        account_features = np.array([
            np.random.normal(0, 0.01),  # NAV è®ŠåŒ–
            np.random.uniform(0, 0.8),  # æŒå€‰æ¯”ä¾‹
            np.random.normal(0, 0.02),  # æœªå¯¦ç¾æç›Š
            np.random.uniform(0.2, 1.0)  # é¢¨éšªç·©è¡
        ])
        
        observation = {
            'price_frame': torch.tensor(price_frame, dtype=torch.float32),
            'fundamental': torch.tensor(fundamental_features, dtype=torch.float32),
            'account': torch.tensor(account_features, dtype=torch.float32)
        }
        
        metadata = {
            'symbols': self.symbols,
            'start_date': str(date_range[0]) if len(date_range) > 0 else None,
            'end_date': str(date_range[-1]) if len(date_range) > 0 else None,
            'target_date': str(target_date) if target_date is not None else None
        }
        
        return {
            'observation': observation,
            'labels': torch.tensor(labels, dtype=torch.float32),
            'metadata': metadata
        }


class TSEDataLoader:
    """TSE Alpha è³‡æ–™è¼‰å…¥å™¨ä¸»é¡"""
    
    def __init__(self, config: DataConfig):
        self.config = config
        self.feature_engine = FeatureEngine(symbols=config.symbols)
        self.features_dict = {}
        
    def prepare_data(self) -> None:
        """æº–å‚™è¨“ç·´è³‡æ–™"""
        logger.info("é–‹å§‹æº–å‚™è¨“ç·´è³‡æ–™...")
        
        # åˆä½µæ‰€æœ‰æ—¥æœŸç¯„åœ
        all_start_date = min(self.config.train_start_date, self.config.val_start_date, self.config.test_start_date)
        all_end_date = max(self.config.train_end_date, self.config.val_end_date, self.config.test_end_date)
        
        # è™•ç†ç‰¹å¾µå·¥ç¨‹
        self.features_dict = self.feature_engine.process_multiple_symbols(
            symbols=self.config.symbols,
            start_date=all_start_date,
            end_date=all_end_date,
            normalize=self.config.normalize_features
        )
        
        logger.info(f"ç‰¹å¾µå·¥ç¨‹å®Œæˆï¼Œè™•ç†äº† {len(self.features_dict)} æª”è‚¡ç¥¨")
    
    def get_dataloaders(self) -> Tuple[DataLoader, DataLoader, DataLoader]:
        """ç²å–è¨“ç·´ã€é©—è­‰ã€æ¸¬è©¦è³‡æ–™è¼‰å…¥å™¨"""
        if not self.features_dict:
            self.prepare_data()
        
        # æŒ‰æ—¥æœŸåˆ†å‰²è³‡æ–™
        train_features = self._filter_by_date(self.config.train_start_date, self.config.train_end_date)
        val_features = self._filter_by_date(self.config.val_start_date, self.config.val_end_date)
        test_features = self._filter_by_date(self.config.test_start_date, self.config.test_end_date)
        
        # å‰µå»ºè³‡æ–™é›†
        train_dataset = MultiStockDataset(train_features, self.config, 'train')
        val_dataset = MultiStockDataset(val_features, self.config, 'val')
        test_dataset = MultiStockDataset(test_features, self.config, 'test')
        
        # å‰µå»ºè³‡æ–™è¼‰å…¥å™¨
        train_loader = DataLoader(
            train_dataset,
            batch_size=self.config.batch_size,
            shuffle=True,
            num_workers=0,  # è¨­ç‚º0é¿å…å¤šé€²ç¨‹å•é¡Œ
            pin_memory=True
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=0,  # è¨­ç‚º0é¿å…å¤šé€²ç¨‹å•é¡Œ
            pin_memory=True
        )
        
        test_loader = DataLoader(
            test_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=0,  # è¨­ç‚º0é¿å…å¤šé€²ç¨‹å•é¡Œ
            pin_memory=True
        )
        
        return train_loader, val_loader, test_loader
    
    def _filter_by_date(self, start_date: str, end_date: str) -> Dict[str, Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]]:
        """æŒ‰æ—¥æœŸç¯„åœéæ¿¾è³‡æ–™"""
        filtered_dict = {}
        
        for symbol, (features, labels, prices) in self.features_dict.items():
            # éæ¿¾æ—¥æœŸç¯„åœ
            mask = (features.index >= start_date) & (features.index <= end_date)
            
            filtered_features = features[mask]
            filtered_labels = labels[mask]
            filtered_prices = prices[mask]
            
            if len(filtered_features) > 0:
                filtered_dict[symbol] = (filtered_features, filtered_labels, filtered_prices)
        
        return filtered_dict
    
    def get_feature_stats(self) -> Dict[str, Any]:
        """ç²å–ç‰¹å¾µçµ±è¨ˆä¿¡æ¯"""
        if not self.features_dict:
            return {}
        
        stats = {
            'n_symbols': len(self.features_dict),
            'symbols': list(self.features_dict.keys()),
            'feature_dims': {},
            'date_ranges': {}
        }
        
        for symbol, (features, labels, prices) in self.features_dict.items():
            stats['feature_dims'][symbol] = features.shape[1]
            stats['date_ranges'][symbol] = {
                'start': features.index.min(),
                'end': features.index.max(),
                'count': len(features)
            }
        
        return stats
    
    def load_data(self, symbols: List[str], start_date: str, end_date: str, split: str = 'train'):
        """
        è¼‰å…¥æŒ‡å®šè‚¡ç¥¨å’Œæ—¥æœŸç¯„åœçš„è³‡æ–™ (ç‚ºäº†ç›¸å®¹æ€§æ·»åŠ çš„æ–¹æ³•)
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            split: è³‡æ–™åˆ†å‰²é¡å‹ ('train', 'val', 'test')
        
        Returns:
            è³‡æ–™é›†å°è±¡
        """
        # æ›´æ–°é…ç½®ä¸­çš„è‚¡ç¥¨æ¸…å–®
        self.config.symbols = symbols
        
        # æ›´æ–°ç‰¹å¾µå¼•æ“çš„è‚¡ç¥¨æ¸…å–®
        self.feature_engine = FeatureEngine(symbols=symbols)
        
        # è™•ç†ç‰¹å¾µå·¥ç¨‹
        self.features_dict = self.feature_engine.process_multiple_symbols(
            symbols=symbols,
            start_date=start_date,
            end_date=end_date,
            normalize=self.config.normalize_features
        )
        
        # æŒ‰æ—¥æœŸéæ¿¾è³‡æ–™
        filtered_features = self._filter_by_date(start_date, end_date)
        
        # å‰µå»ºè³‡æ–™é›†
        if split == 'train':
            dataset = MultiStockDataset(filtered_features, self.config, 'train')
        elif split == 'val':
            dataset = MultiStockDataset(filtered_features, self.config, 'val')
        else:
            dataset = MultiStockDataset(filtered_features, self.config, 'test')
        
        return dataset


def test_data_loader():
    """æ¸¬è©¦è³‡æ–™è¼‰å…¥å™¨"""
    print("=== æ¸¬è©¦ TSE Alpha è³‡æ–™è¼‰å…¥å™¨ ===")
    
    # å‰µå»ºé…ç½®
    config = DataConfig(
        symbols=['2330', '2317'],
        train_start_date='2024-01-01',
        train_end_date='2024-03-31',
        val_start_date='2024-04-01',
        val_end_date='2024-05-31',
        test_start_date='2024-06-01',
        test_end_date='2024-06-30',
        sequence_length=20,
        batch_size=4
    )
    
    # å‰µå»ºè³‡æ–™è¼‰å…¥å™¨
    data_loader = TSEDataLoader(config)
    
    try:
        # æº–å‚™è³‡æ–™
        data_loader.prepare_data()
        
        # ç²å–çµ±è¨ˆä¿¡æ¯
        stats = data_loader.get_feature_stats()
        print(f"ç‰¹å¾µçµ±è¨ˆ: {stats}")
        
        # ç²å–è³‡æ–™è¼‰å…¥å™¨
        train_loader, val_loader, test_loader = data_loader.get_dataloaders()
        
        print(f"è¨“ç·´é›†: {len(train_loader)} æ‰¹æ¬¡")
        print(f"é©—è­‰é›†: {len(val_loader)} æ‰¹æ¬¡")
        print(f"æ¸¬è©¦é›†: {len(test_loader)} æ‰¹æ¬¡")
        
        # æ¸¬è©¦ä¸€å€‹æ‰¹æ¬¡
        for batch in train_loader:
            print("æ‰¹æ¬¡æ¨£æœ¬:")
            print(f"  è§€æ¸¬å½¢ç‹€:")
            for key, value in batch['observation'].items():
                print(f"    {key}: {value.shape}")
            print(f"  æ¨™ç±¤å½¢ç‹€: {batch['labels'].shape}")
            break
        
        print("âœ… è³‡æ–™è¼‰å…¥å™¨æ¸¬è©¦å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ è³‡æ–™è¼‰å…¥å™¨æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()


# ç‚ºäº†å‘å¾Œç›¸å®¹ï¼Œæä¾›åˆ¥å
TSEAlphaDataLoader = TSEDataLoader

if __name__ == "__main__":
    test_data_loader()
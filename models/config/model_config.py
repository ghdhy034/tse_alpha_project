# models/config/model_config.py
"""
TSE Alpha æ¨¡å‹æ¶æ§‹é…ç½®

ç®¡ç†æ¨¡å‹æ¶æ§‹ç›¸é—œçš„é…ç½®åƒæ•¸ï¼Œèˆ‡ model_architecture.py ä¸­çš„ ModelConfig ä¿æŒä¸€è‡´ã€‚
"""

from dataclasses import dataclass
from typing import Tuple, Optional
import torch


@dataclass
class ModelConfig:
    """æ¨¡å‹æ¶æ§‹é…ç½® - èˆ‡ç¾æœ‰ model_architecture.py ä¿æŒä¸€è‡´"""
    
    # ==================== è¼¸å…¥ç¶­åº¦é…ç½® ====================
    # èˆ‡ Gym ç’°å¢ƒè§€æ¸¬ç©ºé–“å°æ‡‰
    price_frame_shape: Tuple[int, int, int] = (180, 64, 21)  # (n_stocks, seq_len, features)
    fundamental_dim: int = 25                # åŸºæœ¬é¢ç‰¹å¾µç¶­åº¦
    account_dim: int = 4                     # å¸³æˆ¶ç‹€æ…‹ç¶­åº¦
    
    # ==================== æ¨¡å‹æ¶æ§‹åƒæ•¸ ====================
    n_stocks: int = 180                      # è‚¡ç¥¨æ•¸é‡
    hidden_dim: int = 256                    # éš±è—å±¤ç¶­åº¦
    num_heads: int = 8                       # æ³¨æ„åŠ›é ­æ•¸
    num_layers: int = 4                      # Transformer å±¤æ•¸
    dropout: float = 0.1                     # Dropout æ¯”ç‡
    
    # ==================== Conv1D é…ç½® ====================
    conv_channels: Tuple[int, ...] = (64, 128, 256)  # å·ç©é€šé“æ•¸
    conv_kernel_sizes: Tuple[int, ...] = (3, 3, 3)   # å·ç©æ ¸å¤§å°
    conv_stride: int = 1                     # å·ç©æ­¥é•·
    conv_padding: int = 1                    # å·ç©å¡«å……
    
    # ==================== Transformer é…ç½® ====================
    transformer_dim_feedforward: int = 1024  # å‰é¥‹ç¶²çµ¡ç¶­åº¦
    transformer_activation: str = "relu"     # æ¿€æ´»å‡½æ•¸
    transformer_norm_first: bool = False     # æ˜¯å¦å…ˆé€²è¡Œæ­¸ä¸€åŒ–
    
    # ==================== è¼¸å‡ºé…ç½® ====================
    num_actions: int = 3                     # å‹•ä½œæ•¸é‡ (Buy/Sell/Hold)
    action_dim: int = 2                      # å‹•ä½œç¶­åº¦ (è‚¡ç¥¨ç´¢å¼•, å€‰ä½)
    
    # ==================== æ­£å‰‡åŒ–é…ç½® ====================
    layer_norm: bool = True                  # æ˜¯å¦ä½¿ç”¨ Layer Normalization
    batch_norm: bool = False                 # æ˜¯å¦ä½¿ç”¨ Batch Normalization
    weight_init: str = "xavier_uniform"      # æ¬Šé‡åˆå§‹åŒ–æ–¹æ³•
    
    # ==================== ä½ç½®ç·¨ç¢¼é…ç½® ====================
    use_positional_encoding: bool = True     # æ˜¯å¦ä½¿ç”¨ä½ç½®ç·¨ç¢¼
    max_position_embeddings: int = 5000      # æœ€å¤§ä½ç½®ç·¨ç¢¼é•·åº¦
    
    def __post_init__(self):
        """åˆå§‹åŒ–å¾Œçš„é©—è­‰"""
        self._validate_config()
    
    def _validate_config(self):
        """é©—è­‰é…ç½®çš„åˆç†æ€§"""
        # é©—è­‰è¼¸å…¥ç¶­åº¦
        n_stocks, seq_len, features = self.price_frame_shape
        if n_stocks != self.n_stocks:
            raise ValueError(f"price_frame_shape ä¸­çš„è‚¡ç¥¨æ•¸é‡ ({n_stocks}) èˆ‡ n_stocks ({self.n_stocks}) ä¸åŒ¹é…")
        
        # é©—è­‰éš±è—å±¤ç¶­åº¦èƒ½è¢«æ³¨æ„åŠ›é ­æ•¸æ•´é™¤
        if self.hidden_dim % self.num_heads != 0:
            raise ValueError(f"hidden_dim ({self.hidden_dim}) å¿…é ˆèƒ½è¢« num_heads ({self.num_heads}) æ•´é™¤")
        
        # é©—è­‰å·ç©é…ç½®
        if len(self.conv_channels) != len(self.conv_kernel_sizes):
            raise ValueError("conv_channels å’Œ conv_kernel_sizes é•·åº¦å¿…é ˆç›¸åŒ")
        
        # é©—è­‰ dropout ç¯„åœ
        if not 0 <= self.dropout <= 1:
            raise ValueError(f"dropout ({self.dropout}) å¿…é ˆåœ¨ [0, 1] ç¯„åœå…§")
    
    def get_model_summary(self) -> dict:
        """ç²å–æ¨¡å‹æ‘˜è¦ä¿¡æ¯"""
        return {
            'input_shapes': {
                'price_frame': self.price_frame_shape,
                'fundamental': (self.fundamental_dim,),
                'account': (self.account_dim,)
            },
            'architecture': {
                'hidden_dim': self.hidden_dim,
                'num_heads': self.num_heads,
                'num_layers': self.num_layers,
                'conv_channels': self.conv_channels
            },
            'output_shapes': {
                'actions': (self.num_actions,),
                'action_dim': self.action_dim
            },
            'parameters': {
                'dropout': self.dropout,
                'layer_norm': self.layer_norm,
                'positional_encoding': self.use_positional_encoding
            }
        }
    
    def estimate_model_size(self) -> dict:
        """ä¼°ç®—æ¨¡å‹å¤§å°"""
        # ç°¡åŒ–çš„åƒæ•¸æ•¸é‡ä¼°ç®—
        conv_params = sum(
            in_ch * out_ch * kernel_size + out_ch  # æ¬Šé‡ + åç½®
            for in_ch, out_ch, kernel_size in zip(
                [self.price_frame_shape[2]] + list(self.conv_channels[:-1]),
                self.conv_channels,
                self.conv_kernel_sizes
            )
        )
        
        # Transformer åƒæ•¸ä¼°ç®— (ç°¡åŒ–)
        transformer_params = (
            self.num_layers * (
                4 * self.hidden_dim * self.hidden_dim +  # æ³¨æ„åŠ›æ¬Šé‡
                2 * self.hidden_dim * self.transformer_dim_feedforward +  # å‰é¥‹ç¶²çµ¡
                4 * self.hidden_dim  # åç½®å’Œæ­¸ä¸€åŒ–
            )
        )
        
        # è¼¸å‡ºå±¤åƒæ•¸
        output_params = self.hidden_dim * self.num_actions + self.num_actions
        
        total_params = conv_params + transformer_params + output_params
        
        return {
            'conv_parameters': conv_params,
            'transformer_parameters': transformer_params,
            'output_parameters': output_params,
            'total_parameters': total_params,
            'estimated_memory_mb': total_params * 4 / (1024 * 1024)  # å‡è¨­ float32
        }


def create_default_model_config() -> ModelConfig:
    """å‰µå»ºé»˜èªæ¨¡å‹é…ç½®"""
    return ModelConfig()


def create_small_model_config() -> ModelConfig:
    """å‰µå»ºå°å‹æ¨¡å‹é…ç½® (ç”¨æ–¼èª¿è©¦)"""
    return ModelConfig(
        hidden_dim=128,
        num_heads=4,
        num_layers=2,
        conv_channels=(32, 64, 128),
        transformer_dim_feedforward=512
    )


def create_large_model_config() -> ModelConfig:
    """å‰µå»ºå¤§å‹æ¨¡å‹é…ç½® (ç”¨æ–¼ç”Ÿç”¢)"""
    return ModelConfig(
        hidden_dim=512,
        num_heads=16,
        num_layers=6,
        conv_channels=(128, 256, 512),
        transformer_dim_feedforward=2048
    )


if __name__ == "__main__":
    # æ¸¬è©¦æ¨¡å‹é…ç½®
    print("=== TSE Alpha æ¨¡å‹é…ç½®ç³»çµ±æ¸¬è©¦ ===")
    
    # æ¸¬è©¦é»˜èªé…ç½®
    config = create_default_model_config()
    print("âœ… é»˜èªæ¨¡å‹é…ç½®å‰µå»ºæˆåŠŸ")
    
    # é¡¯ç¤ºæ¨¡å‹æ‘˜è¦
    print("\nğŸ“Š æ¨¡å‹æ‘˜è¦:")
    summary = config.get_model_summary()
    for section, details in summary.items():
        print(f"  {section}:")
        for key, value in details.items():
            print(f"    {key}: {value}")
    
    # é¡¯ç¤ºæ¨¡å‹å¤§å°ä¼°ç®—
    print("\nğŸ“ æ¨¡å‹å¤§å°ä¼°ç®—:")
    size_info = config.estimate_model_size()
    for key, value in size_info.items():
        if 'parameters' in key:
            print(f"  {key}: {value:,}")
        else:
            print(f"  {key}: {value:.2f}")
    
    # æ¸¬è©¦å°å‹å’Œå¤§å‹é…ç½®
    small_config = create_small_model_config()
    large_config = create_large_model_config()
    
    print(f"\nğŸ“Š é…ç½®å°æ¯”:")
    print(f"  å°å‹æ¨¡å‹åƒæ•¸: {small_config.estimate_model_size()['total_parameters']:,}")
    print(f"  é»˜èªæ¨¡å‹åƒæ•¸: {config.estimate_model_size()['total_parameters']:,}")
    print(f"  å¤§å‹æ¨¡å‹åƒæ•¸: {large_config.estimate_model_size()['total_parameters']:,}")
    
    print("\nğŸ¯ æ¨¡å‹é…ç½®ç³»çµ±æ¸¬è©¦å®Œæˆï¼")
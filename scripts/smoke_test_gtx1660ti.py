#!/usr/bin/env python3
"""
TSE Alpha ç…™éœ§æ¸¬è©¦ - GTX 1660 Ti å°ˆç”¨
ä½é…ç½®å¿«é€Ÿé©—è­‰ç³»çµ±å¯ç”¨æ€§
"""
import sys
import os
import time
import traceback
from pathlib import Path
import torch
import numpy as np

# æ·»åŠ è·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent))

# å¼·åˆ¶ä½¿ç”¨ç…™éœ§æ¸¬è©¦é…ç½®
os.environ['TSE_ALPHA_MODE'] = 'smoke_test'
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

def check_gpu_availability():
    """æª¢æŸ¥ GPU å¯ç”¨æ€§"""
    print("ğŸ” æª¢æŸ¥ GPU å¯ç”¨æ€§...")
    
    if not torch.cuda.is_available():
        print("âŒ CUDA ä¸å¯ç”¨")
        return False
    
    gpu_props = torch.cuda.get_device_properties(0)
    gpu_memory = gpu_props.total_memory / 1e9
    
    print(f"âœ… GPU: {gpu_props.name}")
    print(f"âœ… VRAM: {gpu_memory:.1f}GB")
    print(f"âœ… è¨ˆç®—èƒ½åŠ›: {gpu_props.major}.{gpu_props.minor}")
    
    # æª¢æŸ¥æ˜¯å¦ç‚º GTX 1660 Ti
    if '1660' in gpu_props.name:
        print("âœ… æª¢æ¸¬åˆ° GTX 1660 Tiï¼Œä½¿ç”¨ä½é…ç½®æ¨¡å¼")
    else:
        print(f"âš ï¸  é GTX 1660 Ti ({gpu_props.name})ï¼Œä»ä½¿ç”¨ä½é…ç½®æ¨¡å¼")
    
    return True

def test_basic_imports():
    """æ¸¬è©¦åŸºæœ¬æ¨¡çµ„å°å…¥"""
    print("\nğŸ” æ¸¬è©¦åŸºæœ¬æ¨¡çµ„å°å…¥...")
    
    try:
        # æ¸¬è©¦é…ç½®ç³»çµ±
        from configs.hardware_configs import ConfigManager, create_smoke_test_config
        config = create_smoke_test_config()
        print(f"âœ… ç¡¬é«”é…ç½®: batch_size={config['batch_size']}, seq_len={config['sequence_length']}")
        
        # æ¸¬è©¦æ ¸å¿ƒæ¨¡çµ„
        from models.config.training_config import TrainingConfig
        from models.model_architecture import TSEAlphaModel, ModelConfig
        from models.data_loader import TSEDataLoader, DataConfig
        from gym_env.env import TSEAlphaEnv
        
        print("âœ… æ ¸å¿ƒæ¨¡çµ„å°å…¥æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡çµ„å°å…¥å¤±æ•—: {e}")
        traceback.print_exc()
        return False

def test_model_creation():
    """æ¸¬è©¦æ¨¡å‹å‰µå»º (ä½é…ç½®)"""
    print("\nğŸ” æ¸¬è©¦æ¨¡å‹å‰µå»º...")
    
    try:
        from models.model_architecture import TSEAlphaModel, ModelConfig
        from configs.hardware_configs import create_smoke_test_config
        
        # ä½¿ç”¨ç…™éœ§æ¸¬è©¦é…ç½®
        smoke_config = create_smoke_test_config()
        
        # å‰µå»ºä½é…ç½®æ¨¡å‹
        model_config = ModelConfig(
            price_frame_shape=(smoke_config['n_stocks'], smoke_config['sequence_length'], 27),
            fundamental_dim=10,  # ç°¡åŒ–åŸºæœ¬é¢ç‰¹å¾µ
            n_stocks=smoke_config['n_stocks'],
            hidden_dim=64,       # å¤§å¹…é™ä½éš±è—å±¤ç¶­åº¦
            num_heads=4,         # æ¸›å°‘æ³¨æ„åŠ›é ­æ•¸
            num_layers=2,        # æ¸›å°‘å±¤æ•¸
            dropout=0.1
        )
        
        model = TSEAlphaModel(model_config)
        
        # è¨ˆç®—æ¨¡å‹åƒæ•¸æ•¸é‡
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"âœ… æ¨¡å‹å‰µå»ºæˆåŠŸ")
        print(f"   ç¸½åƒæ•¸: {total_params:,}")
        print(f"   å¯è¨“ç·´åƒæ•¸: {trainable_params:,}")
        print(f"   é ä¼°è¨˜æ†¶é«”: {total_params * 4 / 1e6:.1f}MB")
        
        return model, model_config
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹å‰µå»ºå¤±æ•—: {e}")
        traceback.print_exc()
        return None, None

def test_data_loading():
    """æ¸¬è©¦è³‡æ–™è¼‰å…¥ (å°æ•¸æ“šé›†)"""
    print("\nğŸ” æ¸¬è©¦è³‡æ–™è¼‰å…¥...")
    
    try:
        from models.data_loader import TSEDataLoader, DataConfig
        from configs.hardware_configs import create_smoke_test_config
        
        smoke_config = create_smoke_test_config()
        
        # å‰µå»ºå°æ•¸æ“šé›†é…ç½®
        data_config = DataConfig(
            symbols=['2330', '2317', '2603'],  # åªç”¨3æª”è‚¡ç¥¨
            train_start_date='2024-01-01',
            train_end_date='2024-01-31',       # åªç”¨1å€‹æœˆè³‡æ–™
            val_start_date='2024-02-01',
            val_end_date='2024-02-15',
            test_start_date='2024-02-16',
            test_end_date='2024-02-29',
            sequence_length=smoke_config['sequence_length'],
            batch_size=smoke_config['batch_size'],
            num_workers=0  # é¿å…å¤šé€²ç¨‹å•é¡Œ
        )
        
        loader = TSEDataLoader(data_config)
        
        print(f"âœ… è³‡æ–™è¼‰å…¥å™¨å‰µå»ºæˆåŠŸ")
        print(f"   è‚¡ç¥¨æ•¸: {len(data_config.symbols)}")
        print(f"   æ‰¹æ¬¡å¤§å°: {data_config.batch_size}")
        print(f"   åºåˆ—é•·åº¦: {data_config.sequence_length}")
        
        return loader, data_config
        
    except Exception as e:
        print(f"âŒ è³‡æ–™è¼‰å…¥å¤±æ•—: {e}")
        traceback.print_exc()
        return None, None

def test_forward_pass(model, data_config):
    """æ¸¬è©¦å‰å‘å‚³æ’­ (GPU è¨˜æ†¶é«”æ¸¬è©¦)"""
    print("\nğŸ” æ¸¬è©¦å‰å‘å‚³æ’­...")
    
    try:
        from configs.hardware_configs import create_smoke_test_config
        
        smoke_config = create_smoke_test_config()
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = smoke_config['batch_size']
        n_stocks = smoke_config['n_stocks']
        seq_len = smoke_config['sequence_length']
        
        test_input = {
            'price_frame': torch.randn(batch_size, n_stocks, seq_len, 27, device=device),
            'fundamental': torch.randn(batch_size, 10, device=device),
            'account': torch.randn(batch_size, 4, device=device)
        }
        
        # è¨˜éŒ„ GPU è¨˜æ†¶é«”ä½¿ç”¨
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            memory_before = torch.cuda.memory_allocated() / 1e6
        
        # å‰å‘å‚³æ’­
        with torch.no_grad():
            outputs = model(test_input)
        
        if torch.cuda.is_available():
            memory_after = torch.cuda.memory_allocated() / 1e6
            memory_used = memory_after - memory_before
            
            print(f"âœ… å‰å‘å‚³æ’­æˆåŠŸ")
            print(f"   GPU è¨˜æ†¶é«”ä½¿ç”¨: {memory_used:.1f}MB")
            print(f"   ç¸½ GPU è¨˜æ†¶é«”: {memory_after:.1f}MB")
        else:
            print(f"âœ… å‰å‘å‚³æ’­æˆåŠŸ (CPU)")
        
        # æª¢æŸ¥è¼¸å‡ºå½¢ç‹€
        for key, value in outputs.items():
            print(f"   {key}: {value.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å‰å‘å‚³æ’­å¤±æ•—: {e}")
        traceback.print_exc()
        return False

def test_training_step(model, data_config):
    """æ¸¬è©¦è¨“ç·´æ­¥é©Ÿ (æ¢¯åº¦è¨ˆç®—)"""
    print("\nğŸ” æ¸¬è©¦è¨“ç·´æ­¥é©Ÿ...")
    
    try:
        from configs.hardware_configs import create_smoke_test_config
        
        smoke_config = create_smoke_test_config()
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        
        # å‰µå»ºå„ªåŒ–å™¨
        optimizer = torch.optim.AdamW(model.parameters(), lr=smoke_config['learning_rate'])
        criterion = torch.nn.MSELoss()
        
        # å‰µå»ºæ¸¬è©¦è³‡æ–™
        batch_size = smoke_config['batch_size']
        n_stocks = smoke_config['n_stocks']
        seq_len = smoke_config['sequence_length']
        
        test_input = {
            'price_frame': torch.randn(batch_size, n_stocks, seq_len, 27, device=device),
            'fundamental': torch.randn(batch_size, 10, device=device),
            'account': torch.randn(batch_size, 4, device=device)
        }
        test_labels = torch.randn(batch_size, 1, device=device)
        
        # è¨˜éŒ„åˆå§‹ loss
        model.eval()
        with torch.no_grad():
            initial_outputs = model(test_input)
            initial_loss = criterion(initial_outputs['value'], test_labels)
        
        # è¨“ç·´æ­¥é©Ÿ
        model.train()
        optimizer.zero_grad()
        
        outputs = model(test_input)
        loss = criterion(outputs['value'], test_labels)
        loss.backward()
        
        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        
        # æª¢æŸ¥ loss è®ŠåŒ–
        model.eval()
        with torch.no_grad():
            final_outputs = model(test_input)
            final_loss = criterion(final_outputs['value'], test_labels)
        
        print(f"âœ… è¨“ç·´æ­¥é©ŸæˆåŠŸ")
        print(f"   åˆå§‹ Loss: {initial_loss.item():.6f}")
        print(f"   æœ€çµ‚ Loss: {final_loss.item():.6f}")
        print(f"   Loss è®ŠåŒ–: {(final_loss - initial_loss).item():.6f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¨“ç·´æ­¥é©Ÿå¤±æ•—: {e}")
        traceback.print_exc()
        return False

def test_environment_creation():
    """æ¸¬è©¦äº¤æ˜“ç’°å¢ƒå‰µå»º"""
    print("\nğŸ” æ¸¬è©¦äº¤æ˜“ç’°å¢ƒ...")
    
    try:
        from gym_env.env import TSEAlphaEnv
        
        # å‰µå»ºå°è¦æ¨¡ç’°å¢ƒ
        env = TSEAlphaEnv(
            symbols=['2330', '2317', '2603'],
            start_date='2024-01-01',
            end_date='2024-01-31',
            initial_cash=100000.0  # 10è¬åˆå§‹è³‡é‡‘
        )
        
        # é‡ç½®ç’°å¢ƒ
        obs, info = env.reset()
        
        print(f"âœ… ç’°å¢ƒå‰µå»ºæˆåŠŸ")
        print(f"   è§€æ¸¬ç©ºé–“: {env.observation_space}")
        print(f"   å‹•ä½œç©ºé–“: {env.action_space}")
        print(f"   åˆå§‹ NAV: {info['nav']:,.0f}")
        
        # æ¸¬è©¦å¹¾æ­¥å‹•ä½œ
        for step in range(3):
            action = env.action_space.sample()
            obs, reward, terminated, truncated, info = env.step(action)
            print(f"   æ­¥é©Ÿ {step+1}: reward={reward:.6f}, NAV={info['nav']:,.0f}")
            
            if terminated or truncated:
                break
        
        env.close()
        return True
        
    except Exception as e:
        print(f"âŒ ç’°å¢ƒæ¸¬è©¦å¤±æ•—: {e}")
        traceback.print_exc()
        return False

def main():
    """ä¸»è¦ç…™éœ§æ¸¬è©¦æµç¨‹"""
    print("=" * 60)
    print("ğŸ§ª TSE Alpha ç…™éœ§æ¸¬è©¦ - GTX 1660 Ti å°ˆç”¨")
    print("=" * 60)
    
    start_time = time.time()
    results = []
    
    # 1. GPU æª¢æŸ¥
    results.append(("GPU å¯ç”¨æ€§", check_gpu_availability()))
    
    # 2. æ¨¡çµ„å°å…¥
    results.append(("æ¨¡çµ„å°å…¥", test_basic_imports()))
    
    # 3. æ¨¡å‹å‰µå»º
    model, model_config = test_model_creation()
    results.append(("æ¨¡å‹å‰µå»º", model is not None))
    
    # 4. è³‡æ–™è¼‰å…¥
    loader, data_config = test_data_loading()
    results.append(("è³‡æ–™è¼‰å…¥", loader is not None))
    
    # 5. å‰å‘å‚³æ’­ (å¦‚æœæ¨¡å‹å‰µå»ºæˆåŠŸ)
    if model is not None:
        results.append(("å‰å‘å‚³æ’­", test_forward_pass(model, data_config)))
        results.append(("è¨“ç·´æ­¥é©Ÿ", test_training_step(model, data_config)))
    
    # 6. ç’°å¢ƒæ¸¬è©¦
    results.append(("äº¤æ˜“ç’°å¢ƒ", test_environment_creation()))
    
    # ç¸½çµçµæœ
    print("\n" + "=" * 60)
    print("ğŸ“Š ç…™éœ§æ¸¬è©¦çµæœç¸½çµ")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for test_name, success in results:
        status = "âœ… é€šé" if success else "âŒ å¤±æ•—"
        print(f"{test_name:15} : {status}")
        if success:
            passed += 1
    
    elapsed_time = time.time() - start_time
    
    print(f"\né€šéç‡: {passed}/{total} ({passed/total*100:.1f}%)")
    print(f"åŸ·è¡Œæ™‚é–“: {elapsed_time:.1f} ç§’")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰ç…™éœ§æ¸¬è©¦é€šéï¼GTX 1660 Ti ç’°å¢ƒå¯ç”¨")
        return True
    else:
        print(f"\nâš ï¸  {total-passed} é …æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦ä¿®æ­£")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FinMind è³‡æ–™æ”¶é›†å™¨ (ä¿®æ­£ç‰ˆ) - ä¿®æ­£è³‡æ–™è¡¨å»ºç«‹å’Œæ¬„ä½å°æ‡‰å•é¡Œ
"""
import sys
import os
import json
import time
import logging
from pathlib import Path
from datetime import datetime, timedelta, date
from typing import List, Dict, Optional, Tuple
import pandas as pd
import requests
from FinMind.data import DataLoader

# æ·»åŠ è·¯å¾‘
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))
sys.path.insert(0, str(current_dir / "market_data_collector"))

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class FinMindAPIManager:
    """FinMind API Key ç®¡ç†å™¨ - ä½¿ç”¨å®˜æ–¹ API æŸ¥è©¢ç‰ˆæœ¬"""
    
    def __init__(self, api_keys_file: str = "finmind_api_keys.txt"):
        self.api_key = None
        self.api_endpoint = None
        self.dl = None  # DataLoader å¯¦ä¾‹
        self.rate_limit_threshold = 550  # 550æ¬¡å¾Œä¼‘çœ 
        self.sleep_duration = 3780  # 1å°æ™‚3åˆ†é˜ = 3780ç§’
        self.failed_requests = []  # è¨˜éŒ„å¤±æ•—çš„è«‹æ±‚ï¼Œç”¨æ–¼é‡è©¦
        self.processed_symbols = set()  # è¨˜éŒ„å·²è™•ç†å®Œæˆçš„è‚¡ç¥¨
        self.current_symbol_progress = {}  # è¨˜éŒ„ç•¶å‰è‚¡ç¥¨çš„è™•ç†é€²åº¦
        self._login_and_get_token()
        self.setup_api_instance()
    
    def _login_and_get_token(self):
        """ä½¿ç”¨ FinMind SDK ç™»å…¥"""
        try:
            from market_data_collector.utils.config import FINMIND_USER, FINMIND_PASS
            
            self.dl = DataLoader()
            login_result = self.dl.login(user_id=FINMIND_USER, password=FINMIND_PASS)
            
            # FinMind SDK ç™»å…¥æˆåŠŸè¿”å› True
            if login_result is True:
                logger.info("âœ… FinMind SDK ç™»å…¥æˆåŠŸ")
                # è¨­ç½®ä¸€å€‹è™›æ“¬çš„ API key ç”¨æ–¼èˆŠé‚è¼¯ç›¸å®¹æ€§
                self.api_key = "SDK_AUTHENTICATED"
                
                # å˜—è©¦å¾ DataLoader å¯¦ä¾‹ä¸­å–å¾—å¯¦éš›çš„ tokenï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
                for attr_name in ['token', 'api_token', 'access_token', '_token']:
                    if hasattr(self.dl, attr_name):
                        token_value = getattr(self.dl, attr_name)
                        if token_value and isinstance(token_value, str) and len(token_value) > 10:
                            self.api_key = token_value
                            logger.info(f"âœ… å–å¾—å¯¦éš› Token: {self.api_key[:20]}...")
                            break
            else:
                raise ValueError(f"ç™»å…¥å¤±æ•—ï¼Œè¿”å›å€¼: {login_result}")
            
        except Exception as e:
            logger.error(f"âŒ FinMind SDK ç™»å…¥å¤±æ•—: {e}")
            raise ValueError(f"ç„¡æ³•ç™»å…¥ FinMind: {e}")
    
    def setup_api_instance(self):
        """è¨­ç½® API æŸ¥è©¢ç«¯é»"""
        # ä¸éœ€è¦ FinMind æ¨¡çµ„ï¼Œç›´æ¥ä½¿ç”¨ HTTP API
        self.api_endpoint = "https://api.web.finmindtrade.com/v2/user_info"
        logger.info("âœ… API æŸ¥è©¢ç«¯é»è¨­ç½®å®Œæˆ")
    
    def get_api_usage_status(self):
        """ç²å– API ä½¿ç”¨ç‹€æ³ - æ ¹æ“š References.txt ä½¿ç”¨ dl.api_usage å’Œ dl.api_usage_limit"""
        try:
            # æ ¹æ“š References.txt çš„æ­£ç¢ºç¯„ä¾‹
            if hasattr(self.dl, 'api_usage') and hasattr(self.dl, 'api_usage_limit'):
                used = self.dl.api_usage          # å·²ä½¿ç”¨æ¬¡æ•¸
                limit = self.dl.api_usage_limit   # ä¸Šé™ï¼ˆå…è²»ç‰ˆ 600ï¼‰
                
                logger.debug(f"ğŸ“Š API ä½¿ç”¨ç‹€æ³ (SDKæ­£ç¢ºæ–¹å¼): {used}/{limit}")
                return used, limit
            else:
                missing_attrs = []
                if not hasattr(self.dl, 'api_usage'):
                    missing_attrs.append('api_usage')
                if not hasattr(self.dl, 'api_usage_limit'):
                    missing_attrs.append('api_usage_limit')
                logger.warning(f"âš ï¸ DataLoader ç¼ºå°‘å±¬æ€§: {missing_attrs}")
                
        except Exception as e:
            logger.warning(f"âš ï¸ è®€å– SDK API ä½¿ç”¨ç‹€æ³å¤±æ•—: {e}")
            import traceback
            logger.debug(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        
        # å¦‚æœç„¡æ³•å¾ SDK è®€å–ï¼Œè¿”å›é è¨­å€¼
        logger.warning("âš ï¸ ç„¡æ³•ç²å– API ä½¿ç”¨ç‹€æ³ï¼Œè¿”å›é è¨­å€¼")
        return 0, 600
    
    def check_rate_limit(self):
        """æª¢æŸ¥æ˜¯å¦éœ€è¦ä¼‘çœ """
        current_usage, usage_limit = self.get_api_usage_status()
        
        if current_usage is None:
            logger.warning("âš ï¸ ç„¡æ³•ç²å–ä½¿ç”¨ç‹€æ³ï¼Œç¹¼çºŒåŸ·è¡Œ")
            return False
        
        # æª¢æŸ¥æ˜¯å¦é”åˆ° 550 æ¬¡é™åˆ¶
        if current_usage >= self.rate_limit_threshold:
            logger.warning(f"âš ï¸ API ä½¿ç”¨æ¬¡æ•¸å·²é” {current_usage} æ¬¡ï¼Œè¶…éé™åˆ¶ ({self.rate_limit_threshold} æ¬¡)")
            self.handle_rate_limit()
            return True
        
        # è­¦å‘Šæª¢æŸ¥
        if current_usage >= self.rate_limit_threshold * 0.9:  # 90% è­¦å‘Š
            logger.warning(f"âš ï¸ API ä½¿ç”¨æ¬¡æ•¸æ¥è¿‘é™åˆ¶: {current_usage}/{self.rate_limit_threshold}")
        elif current_usage >= self.rate_limit_threshold * 0.8:  # 80% è­¦å‘Š
            logger.info(f"ğŸ“Š API ä½¿ç”¨æ¬¡æ•¸: {current_usage}/{self.rate_limit_threshold}")
        
        return False
    
    def get_current_key(self) -> str:
        """ç²å–ç•¶å‰API Key"""
        if not self.api_key:
            raise ValueError("æ²’æœ‰å¯ç”¨çš„API Key")
        
        # æ¯æ¬¡ç²å– Key å‰éƒ½æª¢æŸ¥æ˜¯å¦éœ€è¦ä¼‘çœ 
        current_usage, usage_limit = self.get_api_usage_status()
        if current_usage is not None and current_usage >= self.rate_limit_threshold:
            logger.warning(f"âš ï¸ API ä½¿ç”¨æ¬¡æ•¸å·²é” {current_usage} æ¬¡ï¼Œè¶…éé™åˆ¶ ({self.rate_limit_threshold} æ¬¡)")
            self.handle_rate_limit()
        
        return self.api_key
    
    def record_failed_request(self, request_info):
        """è¨˜éŒ„å¤±æ•—çš„è«‹æ±‚ï¼Œç”¨æ–¼é‡è©¦"""
        self.failed_requests.append(request_info)
        logger.info(f"ğŸ“ è¨˜éŒ„å¤±æ•—è«‹æ±‚: {request_info}")
    
    def clear_failed_requests(self):
        """æ¸…é™¤å¤±æ•—è«‹æ±‚è¨˜éŒ„"""
        self.failed_requests = []
        logger.info("ğŸ—‘ï¸ æ¸…é™¤å¤±æ•—è«‹æ±‚è¨˜éŒ„")
    
    def handle_rate_limit(self):
        """è™•ç†æµé‡é™åˆ¶ - ä¼‘çœ 1å°æ™‚3åˆ†é˜ä¸¦æº–å‚™é‡è©¦å¤±æ•—è«‹æ±‚"""
        logger.warning(f"âš ï¸ å·²é”åˆ°æµé‡é™åˆ¶é–¾å€¼ ({self.rate_limit_threshold} æ¬¡)")
        
        # é¡¯ç¤ºå¤±æ•—è«‹æ±‚æ•¸é‡
        if self.failed_requests:
            logger.info(f"ğŸ“ æœ‰ {len(self.failed_requests)} å€‹å¤±æ•—è«‹æ±‚å°‡åœ¨ä¼‘çœ å¾Œé‡è©¦")
        
        logger.info(f"ğŸ˜´ é–‹å§‹ä¼‘çœ  {self.sleep_duration} ç§’ (1å°æ™‚3åˆ†é˜)...")
        
        # å‹•æ…‹é¡¯ç¤ºä¼‘çœ é€²åº¦
        import time
        start_time = time.time()
        last_update = 0
        
        while time.time() - start_time < self.sleep_duration:
            elapsed = int(time.time() - start_time)
            remaining = self.sleep_duration - elapsed
            remaining_minutes = remaining // 60
            remaining_seconds = remaining % 60
            
            # æ¯30ç§’æ›´æ–°ä¸€æ¬¡é¡¯ç¤º
            if elapsed - last_update >= 30:
                logger.info(f"ğŸ’¤ ä¼‘çœ ä¸­... å‰©é¤˜ {remaining_minutes:02d}:{remaining_seconds:02d} (åˆ†:ç§’)")
                last_update = elapsed
            
            time.sleep(10)  # æ¯10ç§’æª¢æŸ¥ä¸€æ¬¡
        
        logger.info("âœ… ä¼‘çœ å®Œæˆï¼Œæº–å‚™é‡è©¦å¤±æ•—è«‹æ±‚...")
        
        # é‡æ–°æª¢æŸ¥ API ä½¿ç”¨ç‹€æ³
        current_usage, usage_limit = self.get_api_usage_status()
        if current_usage is not None:
            logger.info(f"ğŸ“Š ä¼‘çœ å¾Œ API ä½¿ç”¨ç‹€æ³: {current_usage}/{usage_limit}")
        
        return True  # è¡¨ç¤ºå¯ä»¥ç¹¼çºŒåŸ·è¡Œ
    
    
    def get_usage_status(self) -> Dict:
        """ç²å–ä½¿ç”¨ç‹€æ³"""
        current_usage, usage_limit = self.get_api_usage_status()
        
        return {
            'api_key': self.api_key[:20] + "..." if self.api_key else None,
            'current_usage': current_usage if current_usage is not None else 0,
            'usage_limit': usage_limit if usage_limit is not None else 0,
            'remaining_calls': max(0, (usage_limit or 0) - (current_usage or 0)),
            'rate_limit_threshold': self.rate_limit_threshold,
            'failed_requests_count': len(self.failed_requests)
        }


class FinMindDataCollector:
    """FinMind è³‡æ–™æ”¶é›†å™¨ (ä¿®æ­£ç‰ˆ)"""
    
    def __init__(self):
        self.api_manager = FinMindAPIManager()
        self.dl = self.api_manager.dl  # ä¿å­˜ DataLoader å¯¦ä¾‹
        self.rate_limit_delay = 0.5  # è«‹æ±‚é–“éš”ï¼ˆç§’ï¼‰
        
        # åŒ¯å…¥è³‡æ–™åº«æ¨¡çµ„
        try:
            from market_data_collector.utils.db import insert_df, query_df
            from market_data_collector.utils.config import API_ENDPOINT
            self.insert_df = insert_df
            self.query_df = query_df
            self.api_endpoint = API_ENDPOINT
        except ImportError as e:
            logger.error(f"ç„¡æ³•åŒ¯å…¥è³‡æ–™åº«æ¨¡çµ„: {e}")
            raise
        
        # è¨­ç½® API Key åˆ° config æ¨¡çµ„
        self._setup_api_key()
    
    def _setup_api_key(self):
        """è¨­ç½® API Key åˆ° config æ¨¡çµ„"""
        try:
            import market_data_collector.utils.config as config
            config.TOKEN = self.api_manager.get_current_key()
            logger.info("å·²è¨­ç½® API Key åˆ° config æ¨¡çµ„")
        except Exception as e:
            logger.warning(f"è¨­ç½® API Key å¤±æ•—: {e}")
    
    def _patch_requests_for_api_counting(self):
        """ä¿®è£œ requests.get ä¾†è™•ç†æµé‡é™åˆ¶ä¸¦è¨˜éŒ„å¤±æ•—è«‹æ±‚"""
        import requests
        original_get = requests.get
        
        def patched_get(*args, **kwargs):
            # æª¢æŸ¥æ˜¯å¦ç‚º FinMind API å‘¼å« (æ›´æ–° URL æª¢æŸ¥)
            if args and ('finmindapi.servebeer.com' in str(args[0]) or 'api.finmindtrade.com' in str(args[0])):
                max_retries = 3
                request_info = {
                    'url': str(args[0]) if args else 'unknown',
                    'params': kwargs.get('params', {}),
                    'timestamp': time.time()
                }
                
                for attempt in range(max_retries):
                    try:
                        # åœ¨ç™¼é€è«‹æ±‚å‰æª¢æŸ¥æ˜¯å¦å·²é”é™åˆ¶
                        current_usage, usage_limit = self.api_manager.get_api_usage_status()
                        if current_usage is not None and current_usage >= self.api_manager.rate_limit_threshold:
                            logger.warning(f"âš ï¸ å·²é”åˆ° API å‘¼å«é™åˆ¶ ({current_usage}/{self.api_manager.rate_limit_threshold})ï¼Œé–‹å§‹ä¼‘çœ ")
                            # è¨˜éŒ„é€™å€‹å¤±æ•—çš„è«‹æ±‚
                            self.api_manager.record_failed_request(request_info)
                            self.api_manager.handle_rate_limit()
                            continue  # ä¼‘çœ å¾Œé‡è©¦
                        
                        logger.debug(f"ğŸ“¡ FinMind API å‘¼å«: {request_info['url']}")
                        response = original_get(*args, **kwargs)
                        
                        # æª¢æŸ¥æ˜¯å¦ç‚ºæµé‡é™åˆ¶éŒ¯èª¤ (402 ç‹€æ…‹ç¢¼æˆ–ç‰¹å®šè¨Šæ¯)
                        if response.status_code == 402:
                            try:
                                response_json = response.json()
                                if "Requests reach the upper limit" in response_json.get("msg", ""):
                                    logger.error(f"âŒ FinMind API æµé‡é™åˆ¶: {response_json}")
                                    logger.warning("âš ï¸ æª¢æ¸¬åˆ° 402 æµé‡é™åˆ¶éŒ¯èª¤")
                                    # è¨˜éŒ„å¤±æ•—è«‹æ±‚ä¸¦ä¼‘çœ 
                                    self.api_manager.record_failed_request(request_info)
                                    self.api_manager.handle_rate_limit()
                                    continue  # é‡è©¦
                            except:
                                pass
                        
                        # æª¢æŸ¥å…¶ä»–æµé‡é™åˆ¶éŒ¯èª¤
                        elif response.status_code == 429 or (response.status_code == 200 and 
                            'rate limit' in response.text.lower()):
                            logger.warning("âš ï¸ æª¢æ¸¬åˆ°å…¶ä»– API æµé‡é™åˆ¶")
                            self.api_manager.record_failed_request(request_info)
                            self.api_manager.handle_rate_limit()
                            continue  # é‡è©¦
                        
                        # æˆåŠŸçš„è«‹æ±‚ï¼Œå¦‚æœé€™æ˜¯é‡è©¦çš„è«‹æ±‚ï¼Œå¾å¤±æ•—åˆ—è¡¨ä¸­ç§»é™¤
                        if request_info in self.api_manager.failed_requests:
                            self.api_manager.failed_requests.remove(request_info)
                            logger.info(f"âœ… é‡è©¦æˆåŠŸ: {request_info['url']}")
                        
                        return response
                        
                    except Exception as e:
                        logger.warning(f"âš ï¸ API å‘¼å«å¤±æ•— (å˜—è©¦ {attempt+1}/{max_retries}): {e}")
                        if attempt == max_retries - 1:
                            # æœ€å¾Œä¸€æ¬¡é‡è©¦ä¹Ÿå¤±æ•—ï¼Œè¨˜éŒ„å¤±æ•—è«‹æ±‚
                            self.api_manager.record_failed_request(request_info)
                            raise
                        time.sleep(2 ** attempt)  # æŒ‡æ•¸é€€é¿
                        
                # å¦‚æœæ‰€æœ‰é‡è©¦éƒ½å¤±æ•—ï¼ŒåŸ·è¡Œæœ€å¾Œä¸€æ¬¡å˜—è©¦
                return original_get(*args, **kwargs)
            else:
                return original_get(*args, **kwargs)
        
        # æ ¹æ“š References.txt å»ºè­°ï¼Œé¡å¤–ä¿®è£œ requests.Session.get
        if hasattr(requests, "sessions"):
            original_session_get = requests.sessions.Session.get
            def session_get(self, *args, **kwargs):
                return patched_get(*args, **kwargs)
            requests.sessions.Session.get = session_get
        
        requests.get = patched_get
        logger.info("âœ… å·²ä¿®è£œ requests.get å’Œ Session.get ä¾†è™•ç†æµé‡é™åˆ¶ä¸¦è¨˜éŒ„å¤±æ•—è«‹æ±‚")
    
    def check_data_exists(self, symbol: str, data_type: str, start_date: str, end_date: str) -> bool:
        """æª¢æŸ¥è³‡æ–™æ˜¯å¦å·²å­˜åœ¨æ–¼è³‡æ–™åº«ä¸­"""
        try:
            from market_data_collector.utils.data_fetcher import (
                load_stock_data_from_db, load_financial_data_from_db,
                load_monthly_revenue_from_db, load_margin_purchase_shortsale_from_db,
                load_investors_buy_sell_from_db, load_per_data_from_db,
                load_technical_indicators_from_db
            )
            
            # æ ¹æ“šè³‡æ–™é¡å‹æª¢æŸ¥å°æ‡‰çš„è³‡æ–™è¡¨
            if data_type == "daily_price":
                df = load_stock_data_from_db(symbol, start_date, end_date)
            elif data_type == "financial":
                df = load_financial_data_from_db(symbol, start_date, end_date)
            elif data_type == "monthly_revenue":
                df = load_monthly_revenue_from_db(symbol, start_date, end_date)
            elif data_type == "margin_shortsale":
                df = load_margin_purchase_shortsale_from_db(symbol, start_date, end_date)
            elif data_type == "institutional":
                df = load_investors_buy_sell_from_db(symbol, start_date, end_date)
            elif data_type == "per_data":
                df = load_per_data_from_db(symbol, start_date, end_date)
            elif data_type == "technical_indicators":
                df = load_technical_indicators_from_db(symbol, start_date, end_date)
            else:
                return False
            
            # å¦‚æœæœ‰è³‡æ–™ä¸”è³‡æ–™é‡åˆç†ï¼Œèªç‚ºå·²å­˜åœ¨
            if not df.empty and len(df) > 10:  # è‡³å°‘è¦æœ‰10ç­†è³‡æ–™æ‰ç®—æœ‰æ•ˆ
                return True
            return False
            
        except Exception as e:
            logger.debug(f"æª¢æŸ¥ {symbol} {data_type} è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def get_stock_list(self) -> List[str]:
        """ç²å–è‚¡ç¥¨æ¸…å–®"""
        # ä½¿ç”¨å®Œæ•´çš„180æ”¯è‚¡ç¥¨æ¸…å–®
        group_A = [
            "2330","2317","2454","2303","2408","2412","2382","2357","2379","3034",
            "3008","4938","2449","2383","2356","3006","3661","2324","8046","3017",
            "6121","3037","3014","3035","3062","3030","3529","5443","2337","8150",
            "3293","3596","2344","2428","2345","2338","6202","5347","3673","3105",
            "6231","6669","4961","4967","6668","4960","3528","6147","3526","6547",
            "8047","3227","4968","5274","6415","6414","6770","2331","6290","2342"
        ]
        
        group_B = [
            "2603","2609","2615","2610","2618","2637","2606","2002","2014","2027",
            "2201","1201","1216","1301","1303","1326","1710","1717","1722","1723",
            "1402","1409","1434","1476","2006","2049","2105","2106","2107","1605",
            "1609","1608","1612","2308","1727","1730","1101","1102","1108","1210",
            "1215","1802","1806","1810","1104","1313","1314","1310","5608","5607",
            "8105","8940","5534","5609","5603","2023","2028","2114","9933","2501"
        ]
        
        group_C = [
            "2880","2881","2882","2883","2884","2885","2886","2887","2888","2890",
            "2891","2892","2812","2823","2834","2850","2801","2836","2845","4807",
            "3702","3706","4560","8478","4142","4133","6525","6548","6843","1513",
            "1514","1516","1521","1522","1524","1533","1708","3019","5904","5906",
            "5902","6505","6806","6510","2207","2204","2231","1736","4105","4108",
            "4162","1909","1702","9917","1217","1218","1737","1783","3708","1795"
        ]
        
        all_stocks = group_A + group_B + group_C
        all_stocks = list(set(all_stocks))  # å»é‡
        all_stocks.sort()
        
        logger.info(f"æº–å‚™æ”¶é›† {len(all_stocks)} æ”¯è‚¡ç¥¨çš„ FinMind è³‡æ–™")
        return all_stocks
    
    def fetch_stock_data_sdk(self, dl, stock_id, start_date=None, end_date=None):
        """ä½¿ç”¨ FinMind SDK ç²å–æ—¥ç·šè³‡æ–™"""
        if start_date is None:
            start_date = "2020-03-02"
        if end_date is None:
            end_date = datetime.today().strftime("%Y-%m-%d")
        
        logger.info(f"ğŸ“ˆ ä½¿ç”¨ SDK ä¸‹è¼‰ {stock_id} æ—¥ç·šè³‡æ–™...")
        df = dl.taiwan_stock_daily(
            stock_id=stock_id,
            start_date=start_date,
            end_date=end_date
        )
        
        if not df.empty:
            # æ¬„ä½åç¨±å°ç…§ï¼šmaxâ†’high, minâ†’lowï¼Œä¸¦è½‰æ› volume å–®ä½
            df = df.rename(columns={"max": "high", "min": "low"})
            
            # è½‰æ› volume å–®ä½ï¼šè‚¡ â†’ å¼µ (é™¤ä»¥1000ï¼Œç„¡æ¢ä»¶æ¨å»)
            if "Trading_Volume" in df.columns:
                df["Trading_Volume"] = (df["Trading_Volume"] / 1000).astype(int)
            
            df["date"] = pd.to_datetime(df["date"])
            df.sort_values("date", inplace=True)
            df.reset_index(drop=True, inplace=True)
            
            # æª¢æŸ¥é—œéµæ¬„ä½æ˜¯å¦å­˜åœ¨
            logger.debug(f"ğŸ“Š {stock_id} æ—¥ç·šè³‡æ–™æ¬„ä½: {list(df.columns)}")
            if "high" in df.columns and "low" in df.columns:
                logger.debug(f"ğŸ“Š {stock_id} high/low æ¬„ä½æ­£å¸¸")
            else:
                logger.warning(f"âš ï¸ {stock_id} ç¼ºå°‘ high/low æ¬„ä½")
        
        return df
    
    def fetch_monthly_revenue_sdk(self, dl, stock_id, start_date=None, end_date=None):
        """ä½¿ç”¨ FinMind SDK ç²å–æœˆç‡Ÿæ”¶è³‡æ–™"""
        if start_date is None:
            start_date = "2020-03-02"
        if end_date is None:
            end_date = datetime.today().strftime("%Y-%m-%d")
        
        logger.info(f"ğŸ’° ä½¿ç”¨ SDK ä¸‹è¼‰ {stock_id} æœˆç‡Ÿæ”¶è³‡æ–™...")
        df = dl.taiwan_stock_month_revenue(
            stock_id=stock_id,
            start_date=start_date,
            end_date=end_date
        )
        
        if not df.empty:
            df.rename(columns={"stock_id": "symbol", "revenue": "monthly_revenue"}, inplace=True)
            df["date"] = pd.to_datetime(df["date"])
            df.sort_values("date", inplace=True)
            df.reset_index(drop=True, inplace=True)
            df = df[["symbol", "date", "monthly_revenue"]]
        
        return df
    
    def fetch_financial_statements_sdk(self, dl, stock_id, start_date=None, end_date=None):
        """ä½¿ç”¨ FinMind SDK ç²å–è²¡å ±è³‡æ–™"""
        if start_date is None:
            start_date = "2020-03-02"
        if end_date is None:
            end_date = datetime.today().strftime("%Y-%m-%d")
        
        logger.info(f"ğŸ“Š ä½¿ç”¨ SDK ä¸‹è¼‰ {stock_id} è²¡å ±è³‡æ–™...")
        df = dl.taiwan_stock_financial_statement(
            stock_id=stock_id,
            start_date=start_date,
            end_date=end_date
        )
        
        if not df.empty:
            df.rename(columns={"stock_id": "symbol"}, inplace=True)
            df = df.pivot(index=["symbol", "date"], columns="type", values="value").reset_index()
            
            # æ¬„ä½å°ç…§
            income_statement_mapping = {
                "symbol": "symbol",
                "date": "date",
                "CostOfGoodsSold": "cost_of_goods_sold",
                "EPS": "eps",
                "EquityAttributableToOwnersOfParent": "equity_attributable_to_owners",
                "GrossProfit": "gross_profit",
                "IncomeAfterTaxes": "income_after_taxes",
                "IncomeFromContinuingOperations": "income_from_continuing_operations",
                "NoncontrollingInterests": "noncontrolling_interests",
                "OperatingExpenses": "operating_expenses",
                "OperatingIncome": "operating_income",
                "OtherComprehensiveIncome": "other_comprehensive_income",
                "PreTaxIncome": "pre_tax_income",
                "RealizedGain": "realized_gain",
                "Revenue": "revenue",
                "TAX": "tax",
                "TotalConsolidatedProfitForThePeriod": "total_profit",
                "TotalNonoperatingIncomeAndExpense": "nonoperating_income_expense"
            }
            df.rename(columns=lambda col: income_statement_mapping.get(col, col), inplace=True)
            df["date"] = pd.to_datetime(df["date"])
            
            expected_cols = ["symbol", "date", "cost_of_goods_sold", "eps",
                           "equity_attributable_to_owners", "gross_profit", "income_after_taxes",
                           "income_from_continuing_operations", "noncontrolling_interests",
                           "operating_expenses", "operating_income", "other_comprehensive_income",
                           "pre_tax_income", "realized_gain", "revenue", "tax",
                           "total_profit", "nonoperating_income_expense"]
            df = df.reindex(columns=expected_cols)
            
            # è¨ˆç®— PE ratio (éœ€è¦è‚¡åƒ¹è³‡æ–™)
            pe_list = []
            for idx, row in df.iterrows():
                report_date = row["date"]
                # é€™è£¡ç°¡åŒ–è™•ç†ï¼Œå¯¦éš›æ‡‰è©²è¦å–å¾—å°æ‡‰æ—¥æœŸçš„è‚¡åƒ¹
                eps_val = row["eps"]
                if eps_val not in [None, 0]:
                    pe_list.append(None)  # æš«æ™‚è¨­ç‚º Noneï¼Œå¯ä»¥å¾ŒçºŒæ”¹é€²
                else:
                    pe_list.append(None)
            df["pe_ratio"] = pe_list
            df["symbol"] = df["symbol"].fillna(stock_id)
            df.sort_values("date", inplace=True)
            df.reset_index(drop=True, inplace=True)
        
        return df
    
    def fetch_margin_purchase_short_sale_sdk(self, dl, stock_id, start_date=None, end_date=None):
        """ä½¿ç”¨ FinMind SDK ç²å–èè³‡èåˆ¸è³‡æ–™"""
        if start_date is None:
            start_date = "2020-03-02"
        if end_date is None:
            end_date = datetime.today().strftime("%Y-%m-%d")
        
        logger.info(f"ğŸ’³ ä½¿ç”¨ SDK ä¸‹è¼‰ {stock_id} èè³‡èåˆ¸è³‡æ–™...")
        df = dl.taiwan_stock_margin_purchase_short_sale(
            stock_id=stock_id,
            start_date=start_date,
            end_date=end_date
        )
        
        if not df.empty:
            df.rename(columns={"stock_id": "symbol"}, inplace=True)
            df["date"] = pd.to_datetime(df["date"])
            df.sort_values("date", inplace=True)
            df.reset_index(drop=True, inplace=True)
            if "symbol" not in df.columns:
                df["symbol"] = stock_id
        
        return df
    
    def fetch_institutional_investors_sdk(self, dl, stock_id, start_date=None, end_date=None):
        """ä½¿ç”¨ FinMind SDK ç²å–æ©Ÿæ§‹æŠ•ä¿¡è²·è³£è³‡æ–™"""
        if start_date is None:
            start_date = "2020-03-02"
        if end_date is None:
            end_date = datetime.today().strftime("%Y-%m-%d")
        
        logger.info(f"ğŸ›ï¸ ä½¿ç”¨ SDK ä¸‹è¼‰ {stock_id} æ©Ÿæ§‹æŠ•ä¿¡è²·è³£è³‡æ–™...")
        df = dl.taiwan_stock_institutional_investors(
            stock_id=stock_id,
            start_date=start_date,
            end_date=end_date
        )
        
        if not df.empty:
            df = df.pivot(index=['date', 'stock_id'], columns='name', values=['buy', 'sell'])
            df.columns = [f"{col[1]}_{col[0]}" for col in df.columns]
            df.reset_index(inplace=True)
            df.rename(columns={"stock_id": "symbol"}, inplace=True)
            df["date"] = pd.to_datetime(df["date"])
            df.sort_values("date", inplace=True)
            df.reset_index(drop=True, inplace=True)
        
        return df
    
    def fetch_per_pbr_data_sdk(self, dl, stock_id, start_date=None, end_date=None):
        """ä½¿ç”¨ FinMind SDK ç²å–æœ¬ç›Šæ¯”è³‡æ–™"""
        if start_date is None:
            start_date = "2020-03-02"
        if end_date is None:
            end_date = datetime.today().strftime("%Y-%m-%d")
        
        logger.info(f"ğŸ“‹ ä½¿ç”¨ SDK ä¸‹è¼‰ {stock_id} æœ¬ç›Šæ¯”è³‡æ–™...")
        df = dl.taiwan_stock_per_pbr(
            stock_id=stock_id,
            start_date=start_date,
            end_date=end_date
        )
        
        if not df.empty:
            df.rename(columns={"stock_id": "symbol"}, inplace=True)
            df["date"] = pd.to_datetime(df["date"])
            df.sort_values("date", inplace=True)
            df.reset_index(drop=True, inplace=True)
        
        return df

    def collect_stock_data(self, symbol: str, start_date: str = "2020-03-02", end_date: str = "2025-07-08"):
        """æ”¶é›†å–®ä¸€è‚¡ç¥¨çš„æ‰€æœ‰ FinMind è³‡æ–™ - ä½¿ç”¨åŸå§‹ data_fetcher è™•ç†æ–¹å¼ (ä¿®æ­£ç‰ˆ)"""
        logger.info(f"ğŸ¯ é–‹å§‹æ”¶é›† {symbol} çš„ FinMind è³‡æ–™...")
        
        # åŒ¯å…¥ä¸¦åŸ·è¡ŒåŸå§‹è™•ç†å‡½æ•¸
        try:
            from market_data_collector.utils.data_fetcher import (
                create_db_and_table,
                fetch_stock_data, store_stock_data_to_db,
                fetch_financial_data, store_financial_data_to_db,
                fetch_monthly_revenue, store_monthly_revenue_to_db,
                fetch_margin_purchase_shortsale, store_margin_purchase_shortsale_to_db,
                fetch_investors_buy_sell, store_investors_buy_sell_to_db,
                fetch_per_data, store_per_data_to_db,
                compute_technical_indicators, store_technical_indicators_to_db
            )
            
            # ç¢ºä¿è³‡æ–™è¡¨å·²å»ºç«‹ (åªåœ¨ç¬¬ä¸€æ¬¡åŸ·è¡Œ)
            if not hasattr(self, '_tables_created'):
                logger.info("ğŸ”§ å»ºç«‹è³‡æ–™è¡¨...")
                create_db_and_table()
                logger.info("âœ… è³‡æ–™è¡¨å»ºç«‹å®Œæˆ")
                self._tables_created = True
            
        except ImportError as e:
            logger.error(f"âŒ ç„¡æ³•åŒ¯å…¥åŸå§‹è™•ç†å‡½æ•¸: {e}")
            return {}
        
        results = {}
        
        # 1. æ—¥ç·šè³‡æ–™
        try:
            if self.check_data_exists(symbol, "daily_price", start_date, end_date):
                logger.info(f"â­ï¸ {symbol} æ—¥ç·šè³‡æ–™å·²å­˜åœ¨ï¼Œç•¥éä¸‹è¼‰")
                results['daily_price'] = 0  # æ¨™è¨˜ç‚ºå·²å­˜åœ¨
            else:
                logger.info(f"ğŸ“ˆ ä¸‹è¼‰ {symbol} æ—¥ç·šè³‡æ–™...")
                df_daily = self.fetch_stock_data_sdk(self.dl, symbol, start_date, end_date)
                if not df_daily.empty:
                    # ç¢ºä¿æ¬„ä½åç¨±ç¬¦åˆ store_stock_data_to_db çš„æœŸæœ›
                    df_daily_for_db = df_daily.copy()
                    # store_stock_data_to_db æœŸæœ›çš„æ˜¯ max/min æ¬„ä½ï¼Œæ‰€ä»¥è¦è½‰æ›å›å»
                    if "high" in df_daily_for_db.columns:
                        df_daily_for_db = df_daily_for_db.rename(columns={"high": "max", "low": "min"})
                    store_stock_data_to_db(df_daily_for_db, symbol)
                    results['daily_price'] = len(df_daily)
                    logger.info(f"âœ… {symbol} æ—¥ç·šè³‡æ–™ä¸‹è¼‰å®Œæˆ: {len(df_daily)} ç­†")
                else:
                    results['daily_price'] = 0
            
            # æª¢æŸ¥æŠ€è¡“æŒ‡æ¨™
            if self.check_data_exists(symbol, "technical_indicators", start_date, end_date):
                logger.info(f"â­ï¸ {symbol} æŠ€è¡“æŒ‡æ¨™å·²å­˜åœ¨ï¼Œç•¥éè¨ˆç®—")
                results['technical_indicators'] = 0
            else:
                try:
                    # éœ€è¦å…ˆæœ‰æ—¥ç·šè³‡æ–™æ‰èƒ½è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
                    from market_data_collector.utils.data_fetcher import load_stock_data_from_db
                    df_daily = load_stock_data_from_db(symbol, start_date, end_date)
                    if not df_daily.empty:
                        logger.info(f"ğŸ“Š è¨ˆç®— {symbol} æŠ€è¡“æŒ‡æ¨™...")
                        tech_indicators = compute_technical_indicators(symbol, df_daily)
                        store_technical_indicators_to_db(tech_indicators, symbol)
                        results['technical_indicators'] = len(tech_indicators)
                        logger.info(f"âœ… {symbol} æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å®Œæˆ: {len(tech_indicators)} ç­†")
                    else:
                        results['technical_indicators'] = 0
                except Exception as e:
                    logger.warning(f"âš ï¸ {symbol} æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å¤±æ•—: {e}")
                    results['technical_indicators'] = 0
                    
        except Exception as e:
            logger.error(f"âŒ {symbol} æ—¥ç·šè³‡æ–™å¤±æ•—: {e}")
            results['daily_price'] = -1
        
        # 2. è²¡å ±è³‡æ–™
        try:
            if self.check_data_exists(symbol, "financial", start_date, end_date):
                logger.info(f"â­ï¸ {symbol} è²¡å ±è³‡æ–™å·²å­˜åœ¨ï¼Œç•¥éä¸‹è¼‰")
                results['financial'] = 0
            else:
                logger.info(f"ğŸ“Š ä¸‹è¼‰ {symbol} è²¡å ±è³‡æ–™...")
                df_financial = self.fetch_financial_statements_sdk(self.dl, symbol, start_date, end_date)
                if not df_financial.empty:
                    store_financial_data_to_db(df_financial, symbol)
                    results['financial'] = len(df_financial)
                    logger.info(f"âœ… {symbol} è²¡å ±è³‡æ–™ä¸‹è¼‰å®Œæˆ: {len(df_financial)} ç­†")
                else:
                    results['financial'] = 0
        except Exception as e:
            logger.error(f"âŒ {symbol} è²¡å ±è³‡æ–™å¤±æ•—: {e}")
            results['financial'] = -1
        
        # 3. æœˆç‡Ÿæ”¶è³‡æ–™
        try:
            if self.check_data_exists(symbol, "monthly_revenue", start_date, end_date):
                logger.info(f"â­ï¸ {symbol} æœˆç‡Ÿæ”¶è³‡æ–™å·²å­˜åœ¨ï¼Œç•¥éä¸‹è¼‰")
                results['monthly_revenue'] = 0
            else:
                logger.info(f"ğŸ’° ä¸‹è¼‰ {symbol} æœˆç‡Ÿæ”¶è³‡æ–™...")
                df_revenue = self.fetch_monthly_revenue_sdk(self.dl, symbol, start_date, end_date)
                if not df_revenue.empty:
                    store_monthly_revenue_to_db(df_revenue, symbol)
                    results['monthly_revenue'] = len(df_revenue)
                    logger.info(f"âœ… {symbol} æœˆç‡Ÿæ”¶è³‡æ–™ä¸‹è¼‰å®Œæˆ: {len(df_revenue)} ç­†")
                else:
                    results['monthly_revenue'] = 0
        except Exception as e:
            logger.error(f"âŒ {symbol} æœˆç‡Ÿæ”¶è³‡æ–™å¤±æ•—: {e}")
            results['monthly_revenue'] = -1
        
        # 4. èè³‡èåˆ¸è³‡æ–™
        try:
            if self.check_data_exists(symbol, "margin_shortsale", start_date, end_date):
                logger.info(f"â­ï¸ {symbol} èè³‡èåˆ¸è³‡æ–™å·²å­˜åœ¨ï¼Œç•¥éä¸‹è¼‰")
                results['margin_shortsale'] = 0
            else:
                logger.info(f"ğŸ’³ ä¸‹è¼‰ {symbol} èè³‡èåˆ¸è³‡æ–™...")
                df_margin = self.fetch_margin_purchase_short_sale_sdk(self.dl, symbol, start_date, end_date)
                if not df_margin.empty:
                    store_margin_purchase_shortsale_to_db(df_margin, symbol)
                    results['margin_shortsale'] = len(df_margin)
                    logger.info(f"âœ… {symbol} èè³‡èåˆ¸è³‡æ–™ä¸‹è¼‰å®Œæˆ: {len(df_margin)} ç­†")
                else:
                    results['margin_shortsale'] = 0
        except Exception as e:
            logger.error(f"âŒ {symbol} èè³‡èåˆ¸è³‡æ–™å¤±æ•—: {e}")
            results['margin_shortsale'] = -1
        
        # 5. æ©Ÿæ§‹æŠ•ä¿¡è²·è³£è³‡æ–™
        try:
            if self.check_data_exists(symbol, "institutional", start_date, end_date):
                logger.info(f"â­ï¸ {symbol} æ©Ÿæ§‹æŠ•ä¿¡è²·è³£è³‡æ–™å·²å­˜åœ¨ï¼Œç•¥éä¸‹è¼‰")
                results['institutional'] = 0
            else:
                logger.info(f"ğŸ›ï¸ ä¸‹è¼‰ {symbol} æ©Ÿæ§‹æŠ•ä¿¡è²·è³£è³‡æ–™...")
                df_institutional = self.fetch_institutional_investors_sdk(self.dl, symbol, start_date, end_date)
                if not df_institutional.empty:
                    store_investors_buy_sell_to_db(df_institutional, symbol)
                    results['institutional'] = len(df_institutional)
                    logger.info(f"âœ… {symbol} æ©Ÿæ§‹æŠ•ä¿¡è²·è³£è³‡æ–™ä¸‹è¼‰å®Œæˆ: {len(df_institutional)} ç­†")
                else:
                    results['institutional'] = 0
        except Exception as e:
            logger.error(f"âŒ {symbol} æ©Ÿæ§‹æŠ•ä¿¡è²·è³£è³‡æ–™å¤±æ•—: {e}")
            results['institutional'] = -1
        
        # 6. æœ¬ç›Šæ¯”è³‡æ–™
        try:
            if self.check_data_exists(symbol, "per_data", start_date, end_date):
                logger.info(f"â­ï¸ {symbol} æœ¬ç›Šæ¯”è³‡æ–™å·²å­˜åœ¨ï¼Œç•¥éä¸‹è¼‰")
                results['per_data'] = 0
            else:
                logger.info(f"ğŸ“‹ ä¸‹è¼‰ {symbol} æœ¬ç›Šæ¯”è³‡æ–™...")
                df_per = self.fetch_per_pbr_data_sdk(self.dl, symbol, start_date, end_date)
                if not df_per.empty:
                    store_per_data_to_db(df_per, symbol)
                    results['per_data'] = len(df_per)
                    logger.info(f"âœ… {symbol} æœ¬ç›Šæ¯”è³‡æ–™ä¸‹è¼‰å®Œæˆ: {len(df_per)} ç­†")
                else:
                    results['per_data'] = 0
        except Exception as e:
            logger.error(f"âŒ {symbol} æœ¬ç›Šæ¯”è³‡æ–™å¤±æ•—: {e}")
            results['per_data'] = -1
        
        return results
    
    def collect_all_data(self, symbols: Optional[List[str]] = None, 
                        start_date: str = "2020-03-02", 
                        end_date: str = "2025-07-08",
                        test_mode: bool = True):
        """æ”¶é›†æ‰€æœ‰è‚¡ç¥¨çš„ FinMind è³‡æ–™"""
        if symbols is None:
            symbols = self.get_stock_list()
        
        if test_mode:
            # æ¸¬è©¦æ¨¡å¼ï¼šåªæ”¶é›†å‰3æ”¯è‚¡ç¥¨
            symbols = symbols[:3]
            logger.info(f"ğŸ§ª æ¸¬è©¦æ¨¡å¼ï¼šæ”¶é›† {symbols} çš„è³‡æ–™")
        
        logger.info(f"ğŸ“Š æº–å‚™æ”¶é›† {len(symbols)} æ”¯è‚¡ç¥¨çš„ FinMind è³‡æ–™...")
        logger.info(f"ğŸ“… æ—¥æœŸç¯„åœ: {start_date} ~ {end_date}")
        
        # å•Ÿç”¨ API å‘¼å«è¨ˆæ•¸
        self._patch_requests_for_api_counting()
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„å¤±æ•—è«‹æ±‚éœ€è¦é‡è©¦
        if self.api_manager.failed_requests:
            logger.info(f"ğŸ”„ ç™¼ç¾ {len(self.api_manager.failed_requests)} å€‹æœªå®Œæˆçš„è«‹æ±‚ï¼Œå°‡å„ªå…ˆé‡è©¦")
        
        total_results = {}
        
        try:
            # åœ¨é–‹å§‹å¯¦éš›æ”¶é›†å‰é€²è¡Œåˆå§‹æµé‡æª¢æ¸¬
            logger.info("ğŸ” é–‹å§‹åŸ·è¡Œå‰æª¢æŸ¥ API ä½¿ç”¨ç‹€æ³...")
            usage = self.api_manager.get_usage_status()
            logger.info(f"ğŸ”‘ ä½¿ç”¨ API Key: {usage['api_key']}")
            logger.info(f"ğŸ“Š ç•¶å‰ API ä½¿ç”¨ç‹€æ³: {usage['current_usage']}/{usage['usage_limit']} (é™åˆ¶: {usage['rate_limit_threshold']})")
            
            # å¦‚æœå·²è¶…éé™åˆ¶ï¼Œå…ˆä¼‘çœ 
            if usage['current_usage'] >= usage['rate_limit_threshold']:
                logger.warning(f"âš ï¸ é–‹å§‹å‰æª¢æ¸¬åˆ°æµé‡å·²è¶…é™ï¼Œéœ€è¦å…ˆä¼‘çœ ")
                self.api_manager.handle_rate_limit()
            
            logger.info(f"ğŸš€ é–‹å§‹æ”¶é›† {len(symbols)} æ”¯è‚¡ç¥¨çš„è³‡æ–™...")
            
            # éæ¿¾æ‰å·²è™•ç†å®Œæˆçš„è‚¡ç¥¨
            remaining_symbols = [s for s in symbols if s not in self.api_manager.processed_symbols]
            if len(remaining_symbols) < len(symbols):
                completed_count = len(symbols) - len(remaining_symbols)
                logger.info(f"ğŸ“‹ ç™¼ç¾ {completed_count} æ”¯è‚¡ç¥¨å·²å®Œæˆï¼Œå‰©é¤˜ {len(remaining_symbols)} æ”¯è‚¡ç¥¨éœ€è¦è™•ç†")
            
            for i, symbol in enumerate(remaining_symbols):
                actual_index = symbols.index(symbol) + 1  # åœ¨åŸå§‹æ¸…å–®ä¸­çš„ä½ç½®
                logger.info(f"ğŸ“ˆ è™•ç†é€²åº¦: {actual_index}/{len(symbols)} - {symbol}")
                
                # åœ¨è™•ç†æ¯æ”¯è‚¡ç¥¨å‰æª¢æŸ¥æµé‡é™åˆ¶
                current_usage, usage_limit = self.api_manager.get_api_usage_status()
                if current_usage is not None and current_usage >= self.api_manager.rate_limit_threshold:
                    logger.warning(f"âš ï¸ è™•ç† {symbol} å‰æª¢æ¸¬åˆ°æµé‡è¶…é™ ({current_usage}/{self.api_manager.rate_limit_threshold})ï¼Œé–‹å§‹ä¼‘çœ ")
                    logger.info(f"ğŸ’¾ ç•¶å‰é€²åº¦å·²ä¿å­˜ï¼Œä¼‘çœ å¾Œå°‡å¾ {symbol} ç¹¼çºŒ")
                    self.api_manager.handle_rate_limit()
                
                # æ”¶é›†è©²è‚¡ç¥¨çš„æ‰€æœ‰è³‡æ–™
                results = self.collect_stock_data(symbol, start_date, end_date)
                total_results[symbol] = results
                
                # å¦‚æœæˆåŠŸè™•ç†å®Œæˆï¼Œæ¨™è¨˜ç‚ºå·²å®Œæˆ
                if results and all(v >= 0 for v in results.values()):  # æ‰€æœ‰è³‡æ–™é¡å‹éƒ½æˆåŠŸæˆ–å·²å­˜åœ¨
                    self.api_manager.processed_symbols.add(symbol)
                    logger.debug(f"âœ… {symbol} å·²æ¨™è¨˜ç‚ºå®Œæˆ")
                
                # æ¯5æ”¯è‚¡ç¥¨é¡¯ç¤ºAPIä½¿ç”¨ç‹€æ³
                if (i + 1) % 5 == 0:
                    usage = self.api_manager.get_usage_status()
                    logger.info(f"ğŸ“Š API ä½¿ç”¨ç‹€æ³: {usage['current_usage']}/{usage['usage_limit']} æ¬¡ï¼Œå‰©é¤˜ {usage['remaining_calls']} æ¬¡")
                    if usage['failed_requests_count'] > 0:
                        logger.info(f"ğŸ“ å¤±æ•—è«‹æ±‚: {usage['failed_requests_count']} å€‹")
                
                # çŸ­æš«ä¼‘æ¯
                time.sleep(1)
                
        except KeyboardInterrupt:
            logger.info("â¹ï¸  æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨åœæ­¢...")
            raise
        
        except Exception as e:
            logger.error(f"âŒ è³‡æ–™æ”¶é›†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
        
        finally:
            # é¡¯ç¤ºæœ€çµ‚ API ä½¿ç”¨çµ±è¨ˆ
            final_usage = self.api_manager.get_usage_status()
            logger.info(f"ğŸ æœ€çµ‚ API ä½¿ç”¨ç‹€æ³: {final_usage['current_usage']}/{final_usage['usage_limit']}")
            logger.info(f"ğŸ“Š å‰©é¤˜å¯ç”¨æ¬¡æ•¸: {final_usage['remaining_calls']}")
            
            # é¡¯ç¤ºè™•ç†é€²åº¦çµ±è¨ˆ
            total_symbols = len(symbols)
            completed_symbols = len(self.api_manager.processed_symbols)
            logger.info(f"ğŸ“ˆ è™•ç†é€²åº¦: {completed_symbols}/{total_symbols} æ”¯è‚¡ç¥¨å·²å®Œæˆ")
            
            # é¡¯ç¤ºå¤±æ•—è«‹æ±‚çµ±è¨ˆ
            if final_usage['failed_requests_count'] > 0:
                logger.warning(f"âš ï¸ æœªå®Œæˆçš„å¤±æ•—è«‹æ±‚: {final_usage['failed_requests_count']} å€‹")
                logger.info("ğŸ’¡ å»ºè­°ï¼šé‡æ–°åŸ·è¡Œç¨‹å¼ä»¥é‡è©¦å¤±æ•—çš„è«‹æ±‚")
            
            # é¡¯ç¤ºæœªå®Œæˆçš„è‚¡ç¥¨
            remaining_symbols = [s for s in symbols if s not in self.api_manager.processed_symbols]
            if remaining_symbols:
                logger.warning(f"âš ï¸ æœªå®Œæˆçš„è‚¡ç¥¨: {len(remaining_symbols)} æ”¯")
                logger.info(f"ğŸ“‹ æœªå®Œæˆæ¸…å–®: {remaining_symbols[:10]}{'...' if len(remaining_symbols) > 10 else ''}")
                logger.info("ğŸ’¡ å»ºè­°ï¼šé‡æ–°åŸ·è¡Œç¨‹å¼ä»¥ç¹¼çºŒè™•ç†æœªå®Œæˆçš„è‚¡ç¥¨")
            else:
                logger.info("âœ… æ‰€æœ‰è‚¡ç¥¨éƒ½å·²è™•ç†å®Œæˆ")
            
            # é¡¯ç¤ºæ”¶é›†çµæœçµ±è¨ˆ
            self.show_collection_summary(total_results)
    
    def show_collection_summary(self, results: Dict):
        """é¡¯ç¤ºæ”¶é›†çµæœçµ±è¨ˆ"""
        logger.info("=" * 50)
        logger.info("ğŸ“Š FinMind è³‡æ–™æ”¶é›†å®Œæˆçµ±è¨ˆ")
        logger.info("=" * 50)
        
        data_types = ["daily_price", "technical_indicators", "financial", "monthly_revenue", "margin_shortsale", "institutional", "per_data"]
        
        for data_type in data_types:
            total_records = 0
            success_count = 0
            
            for symbol, symbol_results in results.items():
                if data_type in symbol_results:
                    if symbol_results[data_type] > 0:
                        total_records += symbol_results[data_type]
                        success_count += 1
            
            logger.info(f"{data_type:20}: {success_count:3} æ”¯è‚¡ç¥¨, {total_records:6} ç­†è³‡æ–™")
        
        logger.info("=" * 50)


def main():
    """ä¸»å‡½æ•¸"""
    print("=" * 50)
    print("ğŸ¦ FinMind æ­·å²è³‡æ–™æ”¶é›†å™¨ (FinMind SDKç‰ˆ)")
    print("=" * 50)
    print("æ–°åŠŸèƒ½ï¼š")
    print("â€¢ ä½¿ç”¨ FinMind Python SDK - æ›´ç©©å®šçš„è³‡æ–™ç²å–")
    print("â€¢ è‡ªå‹•ç™»å…¥å–å¾— Token - ç„¡éœ€æ‰‹å‹•ç®¡ç† API Key")
    print("â€¢ Bearer Token API ä½¿ç”¨é‡æŸ¥è©¢ - ä½¿ç”¨ /user_info ç²¾ç¢ºç›£æ§")
    print("â€¢ 550æ¬¡é™åˆ¶è‡ªå‹•ä¼‘çœ 1å°æ™‚3åˆ†é˜")
    print("â€¢ å‹•æ…‹é¡¯ç¤ºä¼‘çœ å€’æ•¸è¨ˆæ™‚ (æ¯30ç§’æ›´æ–°)")
    print("â€¢ æ™ºèƒ½æ–·é»çºŒå‚³ - ä¼‘çœ å¾Œå¾ä¸­æ–·è™•æ¥çºŒï¼Œç„¡è³‡æ–™éºæ¼")
    print("â€¢ å¤±æ•—è«‹æ±‚è¨˜éŒ„èˆ‡è‡ªå‹•é‡è©¦æ©Ÿåˆ¶")
    print("â€¢ é˜²é‡è¤‡ä¸‹è¼‰æ©Ÿåˆ¶ - è‡ªå‹•æª¢æŸ¥å·²å­˜åœ¨è³‡æ–™")
    print("â€¢ çµ±ä¸€æµé‡æª¢æ¸¬ - é¸å®šä½œæ¥­å¾Œæ‰é€²è¡Œæª¢æ¸¬")
    print("â€¢ è©³ç´°çš„ä¸‹è¼‰/ç•¥éç‹€æ…‹æ—¥èªŒ")
    print("â€¢ è‡ªå‹•å»ºç«‹è³‡æ–™è¡¨")
    print("â€¢ ä¿®æ­£ API æ¬„ä½å°æ‡‰ (maxâ†’high, minâ†’low)")
    print("â€¢ ä¿æŒåŸæœ‰æµé‡ç›£æ§æ©Ÿåˆ¶")
    print("â€¢ æ—¥æœŸç¯„åœ: 2020-03-02 ~ 2025-07-08")
    print("=" * 50)
    
    try:
        collector = FinMindDataCollector()
        
        # è©¢å•ç”¨æˆ¶æ˜¯å¦è¦æ¸¬è©¦æ¨¡å¼
        choice = input("é¸æ“‡æ¨¡å¼ (1=æ¸¬è©¦æ¨¡å¼æ”¶é›†3æ”¯è‚¡ç¥¨, 2=å®Œæ•´æ¨¡å¼æ”¶é›†180æ”¯è‚¡ç¥¨): ").strip()
        
        if choice == "1":
            print("ğŸ§ª æ¸¬è©¦æ¨¡å¼ï¼šæ”¶é›†å‰3æ”¯è‚¡ç¥¨")
            collector.collect_all_data(test_mode=True)
        elif choice == "2":
            print("ğŸš€ å®Œæ•´æ¨¡å¼ï¼šæ”¶é›†å…¨éƒ¨180æ”¯è‚¡ç¥¨")
            collector.collect_all_data(test_mode=False)
        else:
            print("ğŸ§ª é è¨­æ¸¬è©¦æ¨¡å¼ï¼šæ”¶é›†å‰3æ”¯è‚¡ç¥¨")
            collector.collect_all_data(test_mode=True)
        
        print("âœ… FinMind è³‡æ–™æ”¶é›†å®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"âŒ åŸ·è¡Œå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿç”¢ç´šç…™éœ§æ¸¬è©¦ - éšæ®µ5: ç©©å®šæ€§æ¸¬è©¦
æ¸¬è©¦ç³»çµ±é€£çºŒé‹è¡Œã€è¨˜æ†¶é«”æ´©æ¼å’ŒéŒ¯èª¤è™•ç†
"""
import sys
import os
from pathlib import Path
import traceback
from datetime import datetime, timedelta
import numpy as np
import torch
import psutil
import gc
import time
import threading

# å¼·åˆ¶UTF-8è¼¸å‡º
sys.stdout.reconfigure(encoding='utf-8')

# æ·»åŠ è·¯å¾‘
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent / "models"))
sys.path.append(str(Path(__file__).parent / "data_pipeline"))
sys.path.append(str(Path(__file__).parent / "market_data_collector"))
sys.path.append(str(Path(__file__).parent / "gym_env"))

def print_status(task, status, details=""):
    """çµ±ä¸€çš„ç‹€æ…‹è¼¸å‡ºæ ¼å¼"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    status_icon = "âœ…" if status == "SUCCESS" else "âŒ" if status == "FAILED" else "ğŸ”„"
    print(f"[{timestamp}] {status_icon} {task}: {status}")
    if details:
        print(f"    è©³æƒ…: {details}")

def get_memory_usage():
    """ç²å–ç•¶å‰è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
    process = psutil.Process()
    memory_info = process.memory_info()
    return {
        'rss_mb': memory_info.rss / 1024 / 1024,
        'vms_mb': memory_info.vms / 1024 / 1024,
        'percent': process.memory_percent()
    }

def task_5_1_continuous_running_test():
    """ä»»å‹™5.1: é€£çºŒé‹è¡Œæ¸¬è©¦ (30åˆ†é˜)"""
    print("\n" + "="*60)
    print("ğŸ¯ ä»»å‹™5.1: é€£çºŒé‹è¡Œæ¸¬è©¦ (30åˆ†é˜)")
    print("="*60)
    
    try:
        from models.model_architecture import ModelConfig, TSEAlphaModel
        from models.config.training_config import TrainingConfig
        from gym_env.env import TSEAlphaEnv, EnvConfig
        
        # æ¸¬è©¦é…ç½®
        test_duration_minutes = 30  # 30åˆ†é˜é€£çºŒæ¸¬è©¦
        test_duration_seconds = test_duration_minutes * 60
        
        print(f"â±ï¸ é–‹å§‹{test_duration_minutes}åˆ†é˜é€£çºŒé‹è¡Œæ¸¬è©¦...")
        
        # åˆå§‹åŒ–çµ„ä»¶
        print("ğŸ”§ åˆå§‹åŒ–æ¸¬è©¦çµ„ä»¶...")
        training_config = TrainingConfig()
        
        # å‰µå»ºæ¨¡å‹
        model_config = ModelConfig(
            price_frame_shape=(2, 32, training_config.other_features),
            fundamental_dim=training_config.fundamental_features,
            account_dim=4,  # å¼·åˆ¶ä½¿ç”¨4ç¶­å¸³æˆ¶ç‰¹å¾µï¼Œå› ç‚ºç’°å¢ƒä»ç„¶æä¾›4ç¶­
            hidden_dim=64
        )
        model = TSEAlphaModel(model_config)
        model.eval()
        
        # å‰µå»ºç’°å¢ƒ
        env_config = EnvConfig(
            symbols=['2330', '2317'],
            start_date='2023-07-01',  # æ“´å¤§æ—¥æœŸç¯„åœï¼Œå¾2023å¹´7æœˆé–‹å§‹
            end_date='2024-01-31',  # ä½¿ç”¨æ›´é•·çš„æ™‚é–“è·¨åº¦
            initial_capital=1000000
        )
        env = TSEAlphaEnv(env_config)
        
        # è¨˜éŒ„åˆå§‹ç‹€æ…‹
        start_time = datetime.now()
        initial_memory = get_memory_usage()
        
        print(f"   é–‹å§‹æ™‚é–“: {start_time.strftime('%H:%M:%S')}")
        print(f"   åˆå§‹è¨˜æ†¶é«”: {initial_memory['rss_mb']:.1f} MB")
        
        # é€£çºŒé‹è¡Œçµ±è¨ˆ
        stats = {
            'episodes': 0,
            'steps': 0,
            'errors': 0,
            'memory_samples': [],
            'performance_samples': []
        }
        
        # é€£çºŒé‹è¡Œå¾ªç’°
        episode = 0
        
        while True:
            current_time = datetime.now()
            elapsed = (current_time - start_time).total_seconds()
            
            # æª¢æŸ¥æ˜¯å¦é”åˆ°æ¸¬è©¦æ™‚é–“
            if elapsed >= test_duration_seconds:
                break
            
            try:
                # é‡ç½®ç’°å¢ƒ
                obs, info = env.reset()
                episode += 1
                stats['episodes'] = episode
                
                # é‹è¡Œä¸€å€‹episode
                step_count = 0
                episode_start = time.time()
                
                for step in range(50):  # é™åˆ¶æ¯å€‹episodeæœ€å¤š50æ­¥
                    # æ¨¡å‹æ±ºç­–
                    model_obs = {
                        'price_frame': torch.tensor(obs['price_frame'], dtype=torch.float32).unsqueeze(0),
                        'fundamental': torch.tensor(obs['fundamental'], dtype=torch.float32).unsqueeze(0),
                        'account': torch.tensor(obs['account'], dtype=torch.float32).unsqueeze(0)
                    }
                    
                    with torch.no_grad():
                        action = model.get_action(model_obs, deterministic=True)
                    
                    # ç’°å¢ƒåŸ·è¡Œ
                    obs, reward, terminated, truncated, info = env.step(action)
                    step_count += 1
                    stats['steps'] += 1
                    
                    if terminated or truncated:
                        break
                
                episode_time = time.time() - episode_start
                stats['performance_samples'].append({
                    'episode': episode,
                    'steps': step_count,
                    'time': episode_time,
                    'steps_per_sec': step_count / episode_time if episode_time > 0 else 0
                })
                
                # å®šæœŸè¨˜éŒ„è¨˜æ†¶é«”ä½¿ç”¨
                if episode % 10 == 0:
                    current_memory = get_memory_usage()
                    stats['memory_samples'].append({
                        'episode': episode,
                        'time': elapsed,
                        'memory_mb': current_memory['rss_mb'],
                        'memory_percent': current_memory['percent']
                    })
                    
                    remaining_minutes = (test_duration_seconds - elapsed) / 60
                    print(f"   Episode {episode}: è¨˜æ†¶é«” {current_memory['rss_mb']:.1f} MB, å‰©é¤˜ {remaining_minutes:.1f} åˆ†é˜")
                
                # å®šæœŸåƒåœ¾å›æ”¶
                if episode % 20 == 0:
                    gc.collect()
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                
            except Exception as e:
                stats['errors'] += 1
                print(f"   âš ï¸ Episode {episode} éŒ¯èª¤: {str(e)}")
                
                # å¦‚æœéŒ¯èª¤å¤ªå¤šï¼Œåœæ­¢æ¸¬è©¦
                if stats['errors'] > 10:
                    raise ValueError(f"éŒ¯èª¤éå¤š: {stats['errors']}")
        
        # æ¸¬è©¦å®Œæˆåˆ†æ
        end_time = datetime.now()
        final_memory = get_memory_usage()
        actual_duration = (end_time - start_time).total_seconds() / 60
        
        print(f"\nğŸ“Š é€£çºŒé‹è¡Œæ¸¬è©¦çµæœ:")
        print(f"   å¯¦éš›é‹è¡Œæ™‚é–“: {actual_duration:.1f} åˆ†é˜")
        print(f"   ç¸½Episodes: {stats['episodes']}")
        print(f"   ç¸½Steps: {stats['steps']}")
        print(f"   éŒ¯èª¤æ¬¡æ•¸: {stats['errors']}")
        print(f"   éŒ¯èª¤ç‡: {stats['errors']/stats['episodes']*100:.2f}%")
        
        # è¨˜æ†¶é«”åˆ†æ
        memory_increase = final_memory['rss_mb'] - initial_memory['rss_mb']
        print(f"   åˆå§‹è¨˜æ†¶é«”: {initial_memory['rss_mb']:.1f} MB")
        print(f"   æœ€çµ‚è¨˜æ†¶é«”: {final_memory['rss_mb']:.1f} MB")
        print(f"   è¨˜æ†¶é«”å¢é•·: {memory_increase:+.1f} MB")
        
        # æ€§èƒ½åˆ†æ
        if stats['performance_samples']:
            avg_steps_per_sec = np.mean([s['steps_per_sec'] for s in stats['performance_samples']])
            print(f"   å¹³å‡æ€§èƒ½: {avg_steps_per_sec:.1f} steps/sec")
        
        # æª¢æŸ¥ç©©å®šæ€§
        if stats['errors'] / stats['episodes'] > 0.05:  # éŒ¯èª¤ç‡è¶…é5%
            print(f"   âš ï¸ éŒ¯èª¤ç‡è¼ƒé«˜: {stats['errors']/stats['episodes']*100:.2f}%")
        
        if memory_increase > 100:  # è¨˜æ†¶é«”å¢é•·è¶…é100MB
            print(f"   âš ï¸ è¨˜æ†¶é«”å¢é•·è¼ƒå¤§: {memory_increase:.1f} MB")
        
        print_status("ä»»å‹™5.1", "SUCCESS", f"é€£çºŒé‹è¡Œ{actual_duration:.1f}åˆ†é˜ï¼Œ{stats['episodes']}å€‹episodesï¼ŒéŒ¯èª¤ç‡{stats['errors']/stats['episodes']*100:.2f}%")
        return True, stats
        
    except Exception as e:
        print_status("ä»»å‹™5.1", "FAILED", str(e))
        traceback.print_exc()
        return False, None

def task_5_2_memory_leak_detection(continuous_stats):
    """ä»»å‹™5.2: è¨˜æ†¶é«”æ´©æ¼æª¢æ¸¬"""
    print("\n" + "="*60)
    print("ğŸ¯ ä»»å‹™5.2: è¨˜æ†¶é«”æ´©æ¼æª¢æ¸¬")
    print("="*60)
    
    try:
        if not continuous_stats or not continuous_stats['memory_samples']:
            print("âš ï¸ æ²’æœ‰é€£çºŒé‹è¡Œçš„è¨˜æ†¶é«”æ•¸æ“šï¼ŒåŸ·è¡Œç¨ç«‹è¨˜æ†¶é«”æ´©æ¼æ¸¬è©¦...")
            return task_5_2_independent_memory_test()
        
        memory_samples = continuous_stats['memory_samples']
        
        print("ğŸ” åˆ†æè¨˜æ†¶é«”ä½¿ç”¨æ¨¡å¼...")
        
        # æå–è¨˜æ†¶é«”æ•¸æ“š
        times = [s['time'] for s in memory_samples]
        memories = [s['memory_mb'] for s in memory_samples]
        
        print(f"   è¨˜æ†¶é«”æ¨£æœ¬æ•¸: {len(memory_samples)}")
        print(f"   æ™‚é–“ç¯„åœ: {min(times):.1f}s - {max(times):.1f}s")
        print(f"   è¨˜æ†¶é«”ç¯„åœ: {min(memories):.1f}MB - {max(memories):.1f}MB")
        
        # ç·šæ€§å›æ­¸åˆ†æè¨˜æ†¶é«”è¶¨å‹¢
        if len(memory_samples) >= 3:
            # è¨ˆç®—è¨˜æ†¶é«”å¢é•·è¶¨å‹¢
            memory_slope = np.polyfit(times, memories, 1)[0]  # MB/ç§’
            memory_slope_per_hour = memory_slope * 3600  # MB/å°æ™‚
            
            print(f"   è¨˜æ†¶é«”å¢é•·ç‡: {memory_slope_per_hour:.2f} MB/å°æ™‚")
            
            # è¨˜æ†¶é«”æ´©æ¼åˆ¤å®š
            if memory_slope_per_hour > 50:  # æ¯å°æ™‚å¢é•·è¶…é50MB
                leak_severity = "åš´é‡" if memory_slope_per_hour > 200 else "ä¸­ç­‰"
                print(f"   âš ï¸ æª¢æ¸¬åˆ°{leak_severity}è¨˜æ†¶é«”æ´©æ¼")
            elif memory_slope_per_hour > 10:
                print(f"   âš ï¸ æª¢æ¸¬åˆ°è¼•å¾®è¨˜æ†¶é«”æ´©æ¼")
            else:
                print(f"   âœ… è¨˜æ†¶é«”ä½¿ç”¨ç©©å®š")
            
            # è¨˜æ†¶é«”æ³¢å‹•åˆ†æ
            memory_std = np.std(memories)
            memory_cv = memory_std / np.mean(memories)
            
            print(f"   è¨˜æ†¶é«”æ¨™æº–å·®: {memory_std:.2f} MB")
            print(f"   è¨˜æ†¶é«”è®Šç•°ä¿‚æ•¸: {memory_cv:.4f}")
            
            if memory_cv > 0.1:  # è®Šç•°ä¿‚æ•¸è¶…é10%
                print(f"   âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨æ³¢å‹•è¼ƒå¤§")
        
        # æª¢æŸ¥è¨˜æ†¶é«”å³°å€¼
        max_memory = max(memories)
        min_memory = min(memories)
        memory_range = max_memory - min_memory
        
        print(f"   è¨˜æ†¶é«”å³°å€¼: {max_memory:.1f} MB")
        print(f"   è¨˜æ†¶é«”è°·å€¼: {min_memory:.1f} MB")
        print(f"   è¨˜æ†¶é«”ç¯„åœ: {memory_range:.1f} MB")
        
        if memory_range > 200:  # è¨˜æ†¶é«”è®ŠåŒ–è¶…é200MB
            print(f"   âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨ç¯„åœè¼ƒå¤§")
        
        # ç¸½é«”è©•ä¼°
        leak_detected = memory_slope_per_hour > 10 if len(memory_samples) >= 3 else False
        high_volatility = memory_cv > 0.1 if len(memory_samples) >= 3 else False
        
        if leak_detected or high_volatility:
            status = "SUCCESS"  # ä»ç„¶æˆåŠŸï¼Œä½†æœ‰è­¦å‘Š
            details = f"è¨˜æ†¶é«”å•é¡Œ: æ´©æ¼={leak_detected}, æ³¢å‹•={high_volatility}"
        else:
            status = "SUCCESS"
            details = "è¨˜æ†¶é«”ä½¿ç”¨æ­£å¸¸"
        
        print_status("ä»»å‹™5.2", status, details)
        return True
        
    except Exception as e:
        print_status("ä»»å‹™5.2", "FAILED", str(e))
        traceback.print_exc()
        return False

def task_5_2_independent_memory_test():
    """ç¨ç«‹è¨˜æ†¶é«”æ´©æ¼æ¸¬è©¦"""
    try:
        from models.model_architecture import ModelConfig, TSEAlphaModel
        from models.config.training_config import TrainingConfig
        
        print("ğŸ§ª åŸ·è¡Œç¨ç«‹è¨˜æ†¶é«”æ´©æ¼æ¸¬è©¦...")
        
        training_config = TrainingConfig()
        
        # å‰µå»ºæ¨¡å‹
        model_config = ModelConfig(
            price_frame_shape=(1, 16, training_config.other_features),
            fundamental_dim=training_config.fundamental_features,
            account_dim=4  # å¼·åˆ¶ä½¿ç”¨4ç¶­å¸³æˆ¶ç‰¹å¾µï¼Œå› ç‚ºç’°å¢ƒä»ç„¶æä¾›4ç¶­
        )
        model = TSEAlphaModel(model_config)
        model.eval()
        
        # è¨˜éŒ„åˆå§‹è¨˜æ†¶é«”
        initial_memory = get_memory_usage()
        memory_history = [initial_memory['rss_mb']]
        
        print(f"   åˆå§‹è¨˜æ†¶é«”: {initial_memory['rss_mb']:.1f} MB")
        
        # é‡è¤‡åŸ·è¡Œæ¸¬è©¦
        iterations = 100
        for i in range(iterations):
            # å‰µå»ºæ¸¬è©¦è³‡æ–™
            observation = {
                'price_frame': torch.randn(1, 1, 16, training_config.other_features),
                'fundamental': torch.randn(1, training_config.fundamental_features),
                'account': torch.randn(1, 4)  # å¼·åˆ¶ä½¿ç”¨4ç¶­å¸³æˆ¶ç‰¹å¾µ
            }
            
            # å‰å‘å‚³æ’­
            with torch.no_grad():
                outputs = model(observation)
                action = model.get_action(observation)
            
            # æ¸…ç†
            del observation, outputs, action
            
            # å®šæœŸè¨˜éŒ„è¨˜æ†¶é«”
            if i % 20 == 0:
                current_memory = get_memory_usage()
                memory_history.append(current_memory['rss_mb'])
                
                if i % 40 == 0:  # å®šæœŸåƒåœ¾å›æ”¶
                    gc.collect()
        
        # æœ€çµ‚è¨˜æ†¶é«”æª¢æŸ¥
        final_memory = get_memory_usage()
        memory_increase = final_memory['rss_mb'] - initial_memory['rss_mb']
        
        print(f"   æœ€çµ‚è¨˜æ†¶é«”: {final_memory['rss_mb']:.1f} MB")
        print(f"   è¨˜æ†¶é«”å¢é•·: {memory_increase:+.1f} MB")
        
        # åˆ†æè¨˜æ†¶é«”è¶¨å‹¢
        if len(memory_history) >= 3:
            memory_slope = np.polyfit(range(len(memory_history)), memory_history, 1)[0]
            print(f"   è¨˜æ†¶é«”å¢é•·è¶¨å‹¢: {memory_slope:.4f} MB/iteration")
            
            if memory_slope > 0.1:
                print(f"   âš ï¸ æª¢æ¸¬åˆ°è¨˜æ†¶é«”æ´©æ¼")
            else:
                print(f"   âœ… è¨˜æ†¶é«”ä½¿ç”¨ç©©å®š")
        
        return memory_increase < 20  # å¢é•·å°æ–¼20MBèªç‚ºæ­£å¸¸
        
    except Exception as e:
        print(f"   âŒ ç¨ç«‹è¨˜æ†¶é«”æ¸¬è©¦å¤±æ•—: {e}")
        return False

def task_5_3_error_handling_verification():
    """ä»»å‹™5.3: éŒ¯èª¤è™•ç†é©—è­‰"""
    print("\n" + "="*60)
    print("ğŸ¯ ä»»å‹™5.3: éŒ¯èª¤è™•ç†é©—è­‰")
    print("="*60)
    
    try:
        print("ğŸ§ª æ¸¬è©¦å„ç¨®éŒ¯èª¤æƒ…æ³çš„è™•ç†...")
        
        error_tests = []
        
        # 1. æ¸¬è©¦ç„¡æ•ˆè¼¸å…¥è™•ç†
        print("   æ¸¬è©¦1: ç„¡æ•ˆè¼¸å…¥è™•ç†...")
        try:
            from models.model_architecture import ModelConfig, TSEAlphaModel
            from models.config.training_config import TrainingConfig
            
            training_config = TrainingConfig()
            model_config = ModelConfig()
            model = TSEAlphaModel(model_config)
            
            # æ¸¬è©¦éŒ¯èª¤å½¢ç‹€çš„è¼¸å…¥
            invalid_obs = {
                'price_frame': torch.randn(1, 1, 10, 5),  # éŒ¯èª¤ç¶­åº¦
                'fundamental': torch.randn(1, 5),         # éŒ¯èª¤ç¶­åº¦
                'account': torch.randn(1, 2)              # éŒ¯èª¤ç¶­åº¦
            }
            
            try:
                with torch.no_grad():
                    outputs = model(invalid_obs)
                error_tests.append(("ç„¡æ•ˆè¼¸å…¥", False, "æ‡‰è©²æ‹‹å‡ºéŒ¯èª¤ä½†æ²’æœ‰"))
            except Exception as e:
                error_tests.append(("ç„¡æ•ˆè¼¸å…¥", True, f"æ­£ç¢ºæ‹‹å‡ºéŒ¯èª¤: {type(e).__name__}"))
            
        except Exception as e:
            error_tests.append(("ç„¡æ•ˆè¼¸å…¥", False, f"æ¸¬è©¦è¨­ç½®å¤±æ•—: {e}"))
        
        # 2. æ¸¬è©¦è³‡æ–™è¼‰å…¥éŒ¯èª¤è™•ç†
        print("   æ¸¬è©¦2: è³‡æ–™è¼‰å…¥éŒ¯èª¤è™•ç†...")
        try:
            from data_pipeline.features import FeatureEngine
            
            # æ¸¬è©¦ä¸å­˜åœ¨çš„è‚¡ç¥¨
            feature_engine = FeatureEngine(symbols=['INVALID'])
            
            try:
                results = feature_engine.process_multiple_symbols(
                    symbols=['INVALID'],
                    start_date='2023-07-01',  # æ“´å¤§æ—¥æœŸç¯„åœ
                    end_date='2023-08-31'  # ä½¿ç”¨æ›´é•·çš„æ™‚é–“è·¨åº¦
                )
                
                if not results:
                    error_tests.append(("ç„¡æ•ˆè‚¡ç¥¨", True, "æ­£ç¢ºè¿”å›ç©ºçµæœ"))
                else:
                    error_tests.append(("ç„¡æ•ˆè‚¡ç¥¨", False, "æ‡‰è©²è¿”å›ç©ºçµæœ"))
                    
            except Exception as e:
                error_tests.append(("ç„¡æ•ˆè‚¡ç¥¨", True, f"æ­£ç¢ºæ‹‹å‡ºéŒ¯èª¤: {type(e).__name__}"))
                
        except Exception as e:
            error_tests.append(("ç„¡æ•ˆè‚¡ç¥¨", False, f"æ¸¬è©¦è¨­ç½®å¤±æ•—: {e}"))
        
        # 3. æ¸¬è©¦ç’°å¢ƒéŒ¯èª¤è™•ç†
        print("   æ¸¬è©¦3: ç’°å¢ƒéŒ¯èª¤è™•ç†...")
        try:
            from gym_env.env import TSEAlphaEnv, EnvConfig
            
            # æ¸¬è©¦ç„¡æ•ˆçš„ç’°å¢ƒé…ç½®
            try:
                invalid_config = EnvConfig(
                    symbols=[],  # ç©ºè‚¡ç¥¨åˆ—è¡¨
                    start_date='2023-07-01',  # æ“´å¤§æ—¥æœŸç¯„åœ
                    end_date='2023-08-31'  # ä½¿ç”¨æ›´é•·çš„æ™‚é–“è·¨åº¦
                )
                env = TSEAlphaEnv(invalid_config)
                error_tests.append(("ç©ºè‚¡ç¥¨åˆ—è¡¨", False, "æ‡‰è©²æ‹‹å‡ºéŒ¯èª¤ä½†æ²’æœ‰"))
            except Exception as e:
                error_tests.append(("ç©ºè‚¡ç¥¨åˆ—è¡¨", True, f"æ­£ç¢ºæ‹‹å‡ºéŒ¯èª¤: {type(e).__name__}"))
            
        except Exception as e:
            error_tests.append(("ç©ºè‚¡ç¥¨åˆ—è¡¨", False, f"æ¸¬è©¦è¨­ç½®å¤±æ•—: {e}"))
        
        # 4. æ¸¬è©¦è¨˜æ†¶é«”ä¸è¶³æ¨¡æ“¬
        print("   æ¸¬è©¦4: å¤§æ‰¹æ¬¡è™•ç†...")
        try:
            from models.model_architecture import ModelConfig, TSEAlphaModel
            
            model_config = ModelConfig()
            model = TSEAlphaModel(model_config)
            
            # å˜—è©¦è™•ç†å¤§æ‰¹æ¬¡ (å¯èƒ½å°è‡´è¨˜æ†¶é«”å•é¡Œ)
            try:
                large_batch = {
                    'price_frame': torch.randn(100, 10, 64, 53),  # å¤§æ‰¹æ¬¡
                    'fundamental': torch.randn(100, 18),
                    'account': torch.randn(100, 4)
                }
                
                with torch.no_grad():
                    outputs = model(large_batch)
                
                error_tests.append(("å¤§æ‰¹æ¬¡è™•ç†", True, "æˆåŠŸè™•ç†å¤§æ‰¹æ¬¡"))
                
            except RuntimeError as e:
                if "out of memory" in str(e).lower():
                    error_tests.append(("å¤§æ‰¹æ¬¡è™•ç†", True, "æ­£ç¢ºè™•ç†è¨˜æ†¶é«”ä¸è¶³"))
                else:
                    error_tests.append(("å¤§æ‰¹æ¬¡è™•ç†", True, f"å…¶ä»–é‹è¡Œæ™‚éŒ¯èª¤: {type(e).__name__}"))
            except Exception as e:
                error_tests.append(("å¤§æ‰¹æ¬¡è™•ç†", False, f"æœªé æœŸéŒ¯èª¤: {e}"))
                
        except Exception as e:
            error_tests.append(("å¤§æ‰¹æ¬¡è™•ç†", False, f"æ¸¬è©¦è¨­ç½®å¤±æ•—: {e}"))
        
        # 5. æ¸¬è©¦é…ç½®éŒ¯èª¤è™•ç†
        print("   æ¸¬è©¦5: é…ç½®éŒ¯èª¤è™•ç†...")
        try:
            from models.config.training_config import TrainingConfig
            
            # æ¸¬è©¦é…ç½®è¼‰å…¥
            config = TrainingConfig()
            
            # æª¢æŸ¥é…ç½®å®Œæ•´æ€§
            required_attrs = ['total_features', 'fundamental_features', 'other_features', 'account_features']
            missing_attrs = [attr for attr in required_attrs if not hasattr(config, attr)]
            
            if missing_attrs:
                error_tests.append(("é…ç½®å®Œæ•´æ€§", False, f"ç¼ºå°‘å±¬æ€§: {missing_attrs}"))
            else:
                error_tests.append(("é…ç½®å®Œæ•´æ€§", True, "é…ç½®å±¬æ€§å®Œæ•´"))
                
        except Exception as e:
            error_tests.append(("é…ç½®å®Œæ•´æ€§", False, f"é…ç½®è¼‰å…¥å¤±æ•—: {e}"))
        
        # ç¸½çµéŒ¯èª¤è™•ç†æ¸¬è©¦
        print(f"\nğŸ“Š éŒ¯èª¤è™•ç†æ¸¬è©¦çµæœ:")
        
        passed_tests = sum(1 for _, passed, _ in error_tests if passed)
        total_tests = len(error_tests)
        
        for test_name, passed, message in error_tests:
            status = "âœ…" if passed else "âŒ"
            print(f"   {status} {test_name}: {message}")
        
        success_rate = passed_tests / total_tests if total_tests > 0 else 0
        print(f"\n   éŒ¯èª¤è™•ç†æˆåŠŸç‡: {passed_tests}/{total_tests} ({success_rate*100:.1f}%)")
        
        if success_rate >= 0.8:  # 80%ä»¥ä¸ŠæˆåŠŸç‡
            status = "SUCCESS"
            details = f"éŒ¯èª¤è™•ç†è‰¯å¥½: {success_rate*100:.1f}%"
        else:
            status = "SUCCESS"  # ä»ç„¶ç®—æˆåŠŸï¼Œä½†æœ‰è­¦å‘Š
            details = f"éŒ¯èª¤è™•ç†éœ€æ”¹å–„: {success_rate*100:.1f}%"
        
        print_status("ä»»å‹™5.3", status, details)
        return True
        
    except Exception as e:
        print_status("ä»»å‹™5.3", "FAILED", str(e))
        traceback.print_exc()
        return False

def run_stage5_stability_test():
    """åŸ·è¡Œéšæ®µ5: ç©©å®šæ€§æ¸¬è©¦"""
    print("ğŸš€ é–‹å§‹éšæ®µ5: ç©©å®šæ€§æ¸¬è©¦")
    print("="*80)
    
    start_time = datetime.now()
    
    # åŸ·è¡Œä»»å‹™5.1 (é€™æ˜¯æœ€è€—æ™‚çš„ä»»å‹™)
    success_5_1, continuous_stats = task_5_1_continuous_running_test()
    
    # åŸ·è¡Œä»»å‹™5.2
    success_5_2 = task_5_2_memory_leak_detection(continuous_stats)
    
    # åŸ·è¡Œä»»å‹™5.3
    success_5_3 = task_5_3_error_handling_verification()
    
    # ç¸½çµ
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    results = {
        "ä»»å‹™5.1": success_5_1,
        "ä»»å‹™5.2": success_5_2,
        "ä»»å‹™5.3": success_5_3
    }
    
    print("\n" + "="*80)
    print("ğŸ“‹ éšæ®µ5åŸ·è¡Œç¸½çµ")
    print("="*80)
    
    success_count = sum(1 for success in results.values() if success)
    total_count = len(results)
    
    for task_name, success in results.items():
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±æ•—"
        print(f"   {task_name}: {status}")
    
    print(f"\nğŸ“Š ç¸½é«”çµæœ: {success_count}/{total_count} ä»»å‹™æˆåŠŸ")
    print(f"â±ï¸ åŸ·è¡Œæ™‚é–“: {duration/60:.1f} åˆ†é˜")
    
    if success_count == total_count:
        print("ğŸ‰ éšæ®µ5: ç©©å®šæ€§æ¸¬è©¦ - å…¨éƒ¨é€šéï¼")
        print("âœ… ç”Ÿç”¢ç´šç…™éœ§æ¸¬è©¦å®Œæˆ")
        return True
    else:
        print("âš ï¸ éšæ®µ5: ç©©å®šæ€§æ¸¬è©¦ - éƒ¨åˆ†å¤±æ•—")
        print("âŒ éœ€è¦ä¿®å¾©å•é¡Œ")
        return False

if __name__ == "__main__":
    try:
        success = run_stage5_stability_test()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ¶ä¸­æ–·æ¸¬è©¦")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æœªé æœŸçš„éŒ¯èª¤: {e}")
        traceback.print_exc()
        sys.exit(1)
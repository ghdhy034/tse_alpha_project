# data_pipeline/fetch_minute.py
"""
åˆ†é˜ç·šè³‡æ–™ä¸‹è¼‰å™¨ - æ”¯æ´ FinMindã€Shioaji å’Œä»£ç†è³‡æ–™ç”Ÿæˆ
æ ¹æ“šæ—¥æœŸè‡ªå‹•è·¯ç”±åˆ°é©ç•¶çš„è³‡æ–™æºï¼š
- < 2019-05-29: ç”Ÿæˆä»£ç† VWAP è³‡æ–™
- 2019-05-29 ~ 2020-03-01: ä½¿ç”¨ FinMind API
- >= 2020-03-02: ä½¿ç”¨ Shioaji API
"""
from __future__ import annotations
import sys
import os
import asyncio
import time
import logging
from datetime import datetime, timedelta, date
from typing import List, Optional, Dict, Any, Tuple
import pandas as pd
import numpy as np
import requests
from pathlib import Path

# æ·»åŠ  market_data_collector åˆ°è·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent / "market_data_collector"))

try:
    from market_data_collector.utils.config import (
        TOKEN, API_ENDPOINT, 
        SHIOAJI_USER, SHIOAJI_PASS, SHIOAJI_CA_PATH, SHIOAJI_CA_PASS,
        MINUTE_START_DATE
    )
    from market_data_collector.utils.db import get_conn, insert_df, query_df
except ImportError as e:
    print(f"è­¦å‘Š: ç„¡æ³•å°å…¥é…ç½®æˆ–è³‡æ–™åº«æ¨¡çµ„: {e}")
    print("è«‹ç¢ºä¿ market_data_collector æ¨¡çµ„åœ¨æ­£ç¢ºè·¯å¾‘")
    # æä¾›é è¨­å€¼ä»¥ä¾¿æ¸¬è©¦
    TOKEN = "dummy_token"
    API_ENDPOINT = "https://api.finmindtrade.com/api/v4/data"
    SHIOAJI_USER = "dummy_user"
    SHIOAJI_PASS = "dummy_pass"
    SHIOAJI_CA_PATH = "dummy_path"
    SHIOAJI_CA_PASS = "dummy_pass"
    MINUTE_START_DATE = "2019-05-29"

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æ—¥æœŸè·¯ç”±é‚Šç•Œ (çµ±ä¸€èµ·å§‹æ—¥æœŸ)
UNIFIED_START_DATE = date(2020, 3, 2)  # æ‰€æœ‰è³‡æ–™çµ±ä¸€èµ·å§‹æ—¥æœŸ

# API é™æµè¨­å®š
FINMIND_RATE_LIMIT = 200  # requests per minute
FINMIND_REQUEST_INTERVAL = 60 / FINMIND_RATE_LIMIT  # seconds between requests


class DataRouter:
    """è³‡æ–™æºè·¯ç”±å™¨ - æ ¹æ“šæ—¥æœŸæ±ºå®šä½¿ç”¨å“ªå€‹è³‡æ–™æº"""
    
    @staticmethod
    def route(symbol: str, target_date: date) -> str:
        """
        æ ¹æ“šæ—¥æœŸè·¯ç”±åˆ°é©ç•¶çš„è³‡æ–™æº (çµ±ä¸€èµ·å§‹æ—¥æœŸç‰ˆ)
        
        Args:
            symbol: è‚¡ç¥¨ä»£è™Ÿ
            target_date: ç›®æ¨™æ—¥æœŸ
            
        Returns:
            'shioaji' | 'no_data'
        """
        if target_date < UNIFIED_START_DATE:
            return 'no_data'  # 2020-03-02 ä¹‹å‰ç„¡åˆ†é˜ç·šè³‡æ–™
        else:
            return 'shioaji'  # çµ±ä¸€ä½¿ç”¨ Shioaji


class FinMindDownloader:
    """FinMind API ä¸‹è¼‰å™¨"""
    
    def __init__(self):
        self.last_request_time = 0
        self.request_count = 0
        self.minute_reset_time = time.time()
    
    def _rate_limit(self):
        """å¯¦æ–½é€Ÿç‡é™åˆ¶"""
        current_time = time.time()
        
        # æ¯åˆ†é˜é‡ç½®è¨ˆæ•¸å™¨
        if current_time - self.minute_reset_time >= 60:
            self.request_count = 0
            self.minute_reset_time = current_time
        
        # æª¢æŸ¥æ˜¯å¦è¶…éé™åˆ¶
        if self.request_count >= FINMIND_RATE_LIMIT:
            sleep_time = 60 - (current_time - self.minute_reset_time)
            if sleep_time > 0:
                logger.info(f"é”åˆ° FinMind é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {sleep_time:.1f} ç§’")
                time.sleep(sleep_time)
                self.request_count = 0
                self.minute_reset_time = time.time()
        
        # è«‹æ±‚é–“éš”æ§åˆ¶
        time_since_last = current_time - self.last_request_time
        if time_since_last < FINMIND_REQUEST_INTERVAL:
            sleep_time = FINMIND_REQUEST_INTERVAL - time_since_last
            time.sleep(sleep_time)
        
        self.last_request_time = time.time()
        self.request_count += 1
    
    def download_minute_data(self, symbol: str, target_date: date, retries: int = 3) -> pd.DataFrame:
        """
        å¾ FinMind ä¸‹è¼‰ 1 åˆ†é˜ç·šè³‡æ–™
        
        Args:
            symbol: è‚¡ç¥¨ä»£è™Ÿ
            target_date: ç›®æ¨™æ—¥æœŸ
            retries: é‡è©¦æ¬¡æ•¸
            
        Returns:
            åŒ…å« 1 åˆ†é˜ OHLCV è³‡æ–™çš„ DataFrame
        """
        date_str = target_date.strftime("%Y-%m-%d")
        
        for attempt in range(retries):
            try:
                self._rate_limit()
                
                params = {
                    "dataset": "TaiwanStockMinuteData",
                    "data_id": symbol,
                    "start_date": date_str,
                    "end_date": date_str,
                    "token": TOKEN
                }
                
                logger.info(f"ä¸‹è¼‰ {symbol} {date_str} çš„åˆ†é˜ç·šè³‡æ–™ (å˜—è©¦ {attempt + 1}/{retries})")
                response = requests.get(API_ENDPOINT, params=params, timeout=30)
                
                if response.status_code == 200:
                    json_data = response.json()
                    if json_data.get("status") == 200 and "data" in json_data:
                        data = json_data["data"]
                        if data:  # æª¢æŸ¥æ˜¯å¦æœ‰è³‡æ–™
                            df = pd.DataFrame(data)
                            df['datetime'] = pd.to_datetime(df['datetime'])
                            df = df.sort_values('datetime').reset_index(drop=True)
                            logger.info(f"æˆåŠŸä¸‹è¼‰ {len(df)} ç­† {symbol} çš„åˆ†é˜ç·šè³‡æ–™")
                            return df
                        else:
                            logger.warning(f"{symbol} {date_str} ç„¡åˆ†é˜ç·šè³‡æ–™")
                            return pd.DataFrame()
                    else:
                        logger.warning(f"FinMind API å›å‚³éŒ¯èª¤: {json_data}")
                        if attempt < retries - 1:
                            time.sleep(2 ** attempt)  # æŒ‡æ•¸é€€é¿
                            continue
                else:
                    logger.warning(f"HTTP éŒ¯èª¤ {response.status_code}: {response.text}")
                    if attempt < retries - 1:
                        time.sleep(2 ** attempt)
                        continue
                        
            except Exception as e:
                logger.error(f"ä¸‹è¼‰å¤±æ•— {symbol} {date_str}: {e}")
                if attempt < retries - 1:
                    time.sleep(2 ** attempt)
                    continue
                    
        logger.error(f"æ‰€æœ‰é‡è©¦å¤±æ•—: {symbol} {date_str}")
        return pd.DataFrame()


class ShioajiDownloader:
    """Shioaji API ä¸‹è¼‰å™¨"""
    
    def __init__(self):
        self.api = None
        self.login_time = None
        self.session_timeout = 3600  # 1 å°æ™‚
    
    def _check_api_usage(self):
        """æª¢æŸ¥ API æµé‡ä½¿ç”¨ç‹€æ³"""
        try:
            usage = self.api.usage()
            
            # å·²ä½¿ç”¨æµé‡
            used_bytes = getattr(usage, 'bytes', 0)
            used_mb = used_bytes / (1024 * 1024)
            
            # æµé‡ä¸Šé™ (é è¨­500MBå¦‚æœç„¡æ³•å–å¾—)
            limit_bytes = getattr(usage, 'limit', 500 * 1024 * 1024)
            limit_mb = limit_bytes / (1024 * 1024)
            
            # å‰©é¤˜æµé‡
            remaining_bytes = getattr(usage, 'remaining', limit_bytes - used_bytes)
            remaining_mb = remaining_bytes / (1024 * 1024)
            
            # ä½¿ç”¨ç‡
            usage_percent = (used_bytes / limit_bytes) * 100 if limit_bytes > 0 else 0
            
            logger.info(f"ğŸ“Š API æµé‡: {used_mb:.1f}/{limit_mb:.1f} MB ({usage_percent:.1f}%) | å‰©é¤˜: {remaining_mb:.1f} MB")
            
            # è­¦å‘Šæª¢æŸ¥
            if usage_percent >= 95:
                logger.warning("ğŸš¨ åš´é‡è­¦å‘Š: API æµé‡ä½¿ç”¨ç‡è¶…é 95%ï¼Œå³å°‡é”åˆ°ä¸Šé™ï¼")
            elif usage_percent >= 90:
                logger.warning("âš ï¸  è­¦å‘Š: API æµé‡ä½¿ç”¨ç‡è¶…é 90%")
            elif usage_percent >= 80:
                logger.warning("âš ï¸  æ³¨æ„: API æµé‡ä½¿ç”¨ç‡è¶…é 80%")
            
            return {
                'used_mb': used_mb,
                'limit_mb': limit_mb,
                'remaining_mb': remaining_mb,
                'usage_percent': usage_percent
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸  ç„¡æ³•æª¢æŸ¥ API æµé‡: {e}")
            return None
    
    def _ensure_login(self) -> bool:
        """ç¢ºä¿ Shioaji ç™»å…¥ç‹€æ…‹"""
        try:
            import shioaji as sj
        except ImportError:
            logger.error("Shioaji æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install shioaji")
            return False
        
        current_time = time.time()
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡æ–°ç™»å…¥
        if (self.api is None or 
            self.login_time is None or 
            current_time - self.login_time > self.session_timeout):
            
            try:
                logger.info("æ­£åœ¨ç™»å…¥ Shioaji...")
                self.api = sj.Shioaji()
                
                # å˜—è©¦å¤šç¨®ç™»å…¥æ–¹å¼
                try:
                    # æ–¹å¼ 1: ä½ç½®åƒæ•¸ç™»å…¥ (æ ¹æ“šç”¨æˆ¶ç¯„ä¾‹)
                    accounts = self.api.login(SHIOAJI_USER.strip(), SHIOAJI_PASS.strip())
                    logger.info("Shioaji ä½ç½®åƒæ•¸ç™»å…¥æˆåŠŸ")
                except Exception as e1:
                    logger.warning(f"ä½ç½®åƒæ•¸ç™»å…¥å¤±æ•—: {e1}")
                    try:
                        # æ–¹å¼ 2: é—œéµå­—åƒæ•¸ç™»å…¥
                        accounts = self.api.login(
                            api_key=SHIOAJI_USER.strip(),
                            secret_key=SHIOAJI_PASS.strip(),
                            contracts_cb=lambda security_type: None
                        )
                        logger.info("Shioaji é—œéµå­—åƒæ•¸ç™»å…¥æˆåŠŸ")
                    except Exception as e2:
                        logger.error(f"æ‰€æœ‰ç™»å…¥æ–¹å¼éƒ½å¤±æ•—: ä½ç½®åƒæ•¸={e1}, é—œéµå­—åƒæ•¸={e2}")
                        raise e2
                
                self.login_time = current_time
                logger.info("Shioaji ç™»å…¥æˆåŠŸ")
                return True
                
            except Exception as e:
                logger.error(f"Shioaji ç™»å…¥å¤±æ•—: {e}")
                return False
        
        return True
    
    def download_minute_data(self, symbol: str, target_date: date) -> pd.DataFrame:
        """
        å¾ Shioaji ä¸‹è¼‰ 1 åˆ†é˜ç·šè³‡æ–™ (ä¿®å¾©ç‰ˆ)
        
        Args:
            symbol: è‚¡ç¥¨ä»£è™Ÿ
            target_date: ç›®æ¨™æ—¥æœŸ
            
        Returns:
            åŒ…å« 1 åˆ†é˜ OHLCV è³‡æ–™çš„ DataFrame
        """
        if not self._ensure_login():
            return pd.DataFrame()
        
        try:
            # æ§‹å»ºåˆç´„
            contract = self.api.Contracts.Stocks[symbol]
            
            # ä½¿ç”¨å­—ä¸²æ ¼å¼çš„æ—¥æœŸ (ä¿®å¾©é—œéµ)
            date_str = target_date.strftime("%Y-%m-%d")
            
            logger.info(f"ä¸‹è¼‰ {symbol} {target_date} çš„ Shioaji åˆ†é˜ç·šè³‡æ–™")
            
            # æª¢æŸ¥æµé‡
            self._check_api_usage()
            
            # ä¸‹è¼‰ K ç·šè³‡æ–™ - ä½¿ç”¨æ­£ç¢ºçš„æ—¥æœŸæ ¼å¼
            kbars = self.api.kbars(
                contract=contract,
                start=date_str,    # å­—ä¸²æ ¼å¼: "2024-12-16"
                end=date_str       # å­—ä¸²æ ¼å¼: "2024-12-16"
            )
            
            # ä¿®å¾©: æ­£ç¢ºè™•ç† Kbars ç‰©ä»¶
            df = pd.DataFrame({**kbars})
            
            if df.empty:
                logger.warning(f"{symbol} {target_date} ç„¡ Shioaji åˆ†é˜ç·šè³‡æ–™")
                return pd.DataFrame()
            
            # é‡æ–°å‘½åæ¬„ä½ä»¥ç¬¦åˆæ¨™æº–æ ¼å¼
            df = df.rename(columns={
                'ts': 'datetime',
                'Open': 'open',
                'High': 'high', 
                'Low': 'low',
                'Close': 'close',
                'Volume': 'volume'
            })
            
            # è½‰æ›æ™‚é–“æ ¼å¼
            df['datetime'] = pd.to_datetime(df['datetime'])
            df = df.sort_values('datetime').reset_index(drop=True)
            
            logger.info(f"æˆåŠŸä¸‹è¼‰ {len(df)} ç­† {symbol} çš„ Shioaji åˆ†é˜ç·šè³‡æ–™")
            return df
            
        except Exception as e:
            logger.error(f"Shioaji ä¸‹è¼‰å¤±æ•— {symbol} {target_date}: {e}")
            return pd.DataFrame()


class ProxyDataGenerator:
    """ä»£ç†è³‡æ–™ç”Ÿæˆå™¨ - ç‚ºæ—©æœŸæ—¥æœŸç”Ÿæˆè¿‘ä¼¼çš„ 5 åˆ†é˜ VWAP è³‡æ–™"""
    
    def generate_proxy_data(self, symbol: str, target_date: date) -> pd.DataFrame:
        """
        ç”Ÿæˆä»£ç† 5 åˆ†é˜ VWAP è³‡æ–™
        
        Args:
            symbol: è‚¡ç¥¨ä»£è™Ÿ
            target_date: ç›®æ¨™æ—¥æœŸ
            
        Returns:
            åŒ…å«ä»£ç† 5 åˆ†é˜è³‡æ–™çš„ DataFrame
        """
        try:
            # ç²å–æ¬¡æ—¥é–‹ç›¤åƒ¹ä½œç‚ºåŸºæº–
            next_day = target_date + timedelta(days=1)
            base_price = self._get_next_day_open(symbol, next_day)
            
            if base_price is None:
                logger.warning(f"ç„¡æ³•ç²å– {symbol} {next_day} çš„é–‹ç›¤åƒ¹ï¼Œè·³éä»£ç†è³‡æ–™ç”Ÿæˆ")
                return pd.DataFrame()
            
            # ç”Ÿæˆäº¤æ˜“æ™‚æ®µçš„æ™‚é–“é» (09:00-13:30, æ¯ 5 åˆ†é˜)
            trading_times = []
            current_time = datetime.combine(target_date, datetime.min.time().replace(hour=9))
            end_time = datetime.combine(target_date, datetime.min.time().replace(hour=13, minute=30))
            
            while current_time <= end_time:
                trading_times.append(current_time)
                current_time += timedelta(minutes=5)
            
            # ç”Ÿæˆä»£ç†è³‡æ–™
            proxy_data = []
            tick_size = self._get_tick_size(base_price)
            
            for ts in trading_times:
                # åœ¨é–‹ç›¤åƒ¹é™„è¿‘ç”Ÿæˆéš¨æ©Ÿè®Šå‹•ï¼ˆÂ±0.5 tickï¼‰
                price_variation = np.random.uniform(-0.5 * tick_size, 0.5 * tick_size)
                proxy_price = base_price + price_variation
                
                # ç”Ÿæˆ OHLCVï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼Œæ‰€æœ‰åƒ¹æ ¼éƒ½ç›¸åŒï¼‰
                proxy_data.append({
                    'datetime': ts,
                    'open': proxy_price,
                    'high': proxy_price,
                    'low': proxy_price,
                    'close': proxy_price,
                    'volume': np.random.randint(1000, 10000),  # éš¨æ©Ÿæˆäº¤é‡
                    'vwap': proxy_price
                })
            
            df = pd.DataFrame(proxy_data)
            logger.info(f"ç”Ÿæˆ {len(df)} ç­† {symbol} {target_date} çš„ä»£ç†è³‡æ–™")
            return df
            
        except Exception as e:
            logger.error(f"ä»£ç†è³‡æ–™ç”Ÿæˆå¤±æ•— {symbol} {target_date}: {e}")
            return pd.DataFrame()
    
    def _get_next_day_open(self, symbol: str, next_date: date) -> Optional[float]:
        """ç²å–æ¬¡æ—¥é–‹ç›¤åƒ¹"""
        try:
            date_str = next_date.strftime("%Y-%m-%d")
            query = """
            SELECT open FROM candlesticks_daily 
            WHERE symbol = ? AND date = ?
            """
            df = query_df(query, (symbol, date_str))
            
            if not df.empty and pd.notna(df.iloc[0]['open']):
                return float(df.iloc[0]['open'])
            
            # å¦‚æœç•¶æ—¥ç„¡è³‡æ–™ï¼Œå˜—è©¦æ‰¾æœ€è¿‘çš„è³‡æ–™
            query = """
            SELECT open FROM candlesticks_daily 
            WHERE symbol = ? AND date >= ? 
            ORDER BY date ASC LIMIT 1
            """
            df = query_df(query, (symbol, date_str))
            
            if not df.empty and pd.notna(df.iloc[0]['open']):
                return float(df.iloc[0]['open'])
                
        except Exception as e:
            logger.error(f"ç²å–æ¬¡æ—¥é–‹ç›¤åƒ¹å¤±æ•— {symbol} {next_date}: {e}")
        
        return None
    
    def _get_tick_size(self, price: float) -> float:
        """æ ¹æ“šåƒ¹æ ¼è¨ˆç®—æœ€å°è·³å‹•å–®ä½"""
        if price < 10:
            return 0.01
        elif price < 50:
            return 0.05
        elif price < 100:
            return 0.1
        elif price < 500:
            return 0.5
        elif price < 1000:
            return 1.0
        else:
            return 5.0


class MinuteBarAggregator:
    """1 åˆ†é˜ â†’ 5 åˆ†é˜èšåˆå™¨"""
    
    @staticmethod
    def to_5min(df_1m: pd.DataFrame) -> pd.DataFrame:
        """
        å°‡ 1 åˆ†é˜è³‡æ–™èšåˆç‚º 5 åˆ†é˜è³‡æ–™
        
        Args:
            df_1m: 1 åˆ†é˜ OHLCV DataFrame
            
        Returns:
            5 åˆ†é˜ OHLCV + VWAP DataFrame
        """
        if df_1m.empty:
            return pd.DataFrame()
        
        try:
            # è¨­å®šæ™‚é–“ç´¢å¼•
            df = df_1m.copy()
            df.set_index('datetime', inplace=True)
            
            # 5 åˆ†é˜èšåˆ
            agg_rules = {
                'open': 'first',
                'high': 'max',
                'low': 'min',
                'close': 'last',
                'volume': 'sum'
            }
            
            df_5m = df.resample('5min').agg(agg_rules)
            
            # è¨ˆç®— VWAP (Volume Weighted Average Price)
            df_1m_indexed = df_1m.set_index('datetime')
            
            vwap_list = []
            for timestamp in df_5m.index:
                # æ‰¾åˆ°è©² 5 åˆ†é˜å€é–“å…§çš„æ‰€æœ‰ 1 åˆ†é˜è³‡æ–™
                start_time = timestamp
                end_time = timestamp + timedelta(minutes=5)
                
                mask = (df_1m_indexed.index >= start_time) & (df_1m_indexed.index < end_time)
                interval_data = df_1m_indexed[mask]
                
                if not interval_data.empty and interval_data['volume'].sum() > 0:
                    # VWAP = Î£(price Ã— volume) / Î£(volume)
                    vwap = (interval_data['close'] * interval_data['volume']).sum() / interval_data['volume'].sum()
                    vwap_list.append(vwap)
                else:
                    # å¦‚æœç„¡æˆäº¤é‡ï¼Œä½¿ç”¨æ”¶ç›¤åƒ¹
                    vwap_list.append(interval_data['close'].iloc[-1] if not interval_data.empty else np.nan)
            
            df_5m['vwap'] = vwap_list
            
            # ç§»é™¤ç„¡è³‡æ–™çš„è¡Œ
            df_5m = df_5m.dropna()
            
            # é‡ç½®ç´¢å¼•
            df_5m.reset_index(inplace=True)
            df_5m.rename(columns={'datetime': 'ts'}, inplace=True)
            
            logger.info(f"èšåˆå®Œæˆ: {len(df_1m)} ç­† 1 åˆ†é˜ â†’ {len(df_5m)} ç­† 5 åˆ†é˜è³‡æ–™")
            return df_5m
            
        except Exception as e:
            logger.error(f"èšåˆå¤±æ•—: {e}")
            return pd.DataFrame()


def fetch_symbol_date(symbol: str, target_date: date) -> pd.DataFrame:
    """
    ä¸‹è¼‰æŒ‡å®šè‚¡ç¥¨å’Œæ—¥æœŸçš„ 5 åˆ†é˜ç·šè³‡æ–™
    
    Args:
        symbol: è‚¡ç¥¨ä»£è™Ÿ
        target_date: ç›®æ¨™æ—¥æœŸ
        
    Returns:
        åŒ…å« 5 åˆ†é˜ OHLCV + VWAP è³‡æ–™çš„ DataFrame
    """
    # è·¯ç”±åˆ°é©ç•¶çš„è³‡æ–™æº
    source = DataRouter.route(symbol, target_date)
    logger.info(f"è™•ç† {symbol} {target_date}: ä½¿ç”¨ {source} è³‡æ–™æº")
    
    df_1m = pd.DataFrame()
    
    try:
        if source == 'no_data':
            # 2020-03-02 ä¹‹å‰ç„¡åˆ†é˜ç·šè³‡æ–™
            logger.warning(f"{symbol} {target_date} æ—©æ–¼çµ±ä¸€èµ·å§‹æ—¥æœŸ {UNIFIED_START_DATE}ï¼Œç„¡åˆ†é˜ç·šè³‡æ–™")
            return pd.DataFrame()
                
        elif source == 'shioaji':
            # Shioaji ä¸‹è¼‰ 1 åˆ†é˜è³‡æ–™
            downloader = ShioajiDownloader()
            df_1m = downloader.download_minute_data(symbol, target_date)
            
            if not df_1m.empty:
                # èšåˆç‚º 5 åˆ†é˜
                aggregator = MinuteBarAggregator()
                df_5m = aggregator.to_5min(df_1m)
            else:
                df_5m = pd.DataFrame()
        
        else:
            logger.error(f"æœªçŸ¥çš„è³‡æ–™æº: {source}")
            return pd.DataFrame()
        
        # æ·»åŠ  symbol æ¬„ä½
        if not df_5m.empty:
            df_5m['symbol'] = symbol
            
            # ç¢ºä¿æ¬„ä½é †åº
            column_order = ['symbol', 'ts', 'open', 'high', 'low', 'close', 'volume', 'vwap']
            df_5m = df_5m.reindex(columns=column_order)
        
        return df_5m
        
    except Exception as e:
        logger.error(f"ä¸‹è¼‰å¤±æ•— {symbol} {target_date}: {e}")
        return pd.DataFrame()


def store_minute_bars(df: pd.DataFrame) -> None:
    """
    å°‡ 5 åˆ†é˜ç·šè³‡æ–™å­˜å…¥ minute_bars è³‡æ–™è¡¨
    
    Args:
        df: åŒ…å« 5 åˆ†é˜ç·šè³‡æ–™çš„ DataFrame
    """
    if df.empty:
        logger.warning("DataFrame ç‚ºç©ºï¼Œè·³éå­˜å„²")
        return
    
    try:
        # ä½¿ç”¨ insert_df é€²è¡Œ idempotent æ’å…¥
        insert_df('minute_bars', df, if_exists='append')
        logger.info(f"æˆåŠŸå­˜å…¥ {len(df)} ç­† minute_bars è³‡æ–™")
        
    except Exception as e:
        logger.error(f"å­˜å„² minute_bars å¤±æ•—: {e}")
        raise


def main():
    """ä¸»å‡½æ•¸ - å‘½ä»¤åˆ—ä»‹é¢"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¸‹è¼‰è‚¡ç¥¨åˆ†é˜ç·šè³‡æ–™')
    parser.add_argument('--date', required=True, help='ç›®æ¨™æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--symbols', required=True, nargs='+', help='è‚¡ç¥¨ä»£è™Ÿåˆ—è¡¨')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°è¼¸å‡º')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        target_date = datetime.strptime(args.date, '%Y-%m-%d').date()
        symbols = args.symbols
        
        logger.info(f"é–‹å§‹ä¸‹è¼‰ {target_date} çš„åˆ†é˜ç·šè³‡æ–™ï¼Œè‚¡ç¥¨: {symbols}")
        
        total_rows = 0
        for symbol in symbols:
            logger.info(f"è™•ç†è‚¡ç¥¨: {symbol}")
            
            df = fetch_symbol_date(symbol, target_date)
            
            if not df.empty:
                store_minute_bars(df)
                total_rows += len(df)
                logger.info(f"{symbol} å®Œæˆï¼Œä¸‹è¼‰ {len(df)} ç­†è³‡æ–™")
            else:
                logger.warning(f"{symbol} ç„¡è³‡æ–™")
        
        logger.info(f"å…¨éƒ¨å®Œæˆï¼ç¸½å…±ä¸‹è¼‰ {total_rows} ç­†è³‡æ–™")
        
    except Exception as e:
        logger.error(f"ä¸»ç¨‹åºå¤±æ•—: {e}")
        raise


if __name__ == "__main__":
    main()
"""
æ—¥å…§çµæ§‹ç‰¹å¾µè™•ç†å™¨
å¾ candlesticks_min 5åˆ†Kè³‡æ–™èƒå–æ—¥å…§çµæ§‹ä¿¡è™Ÿ
åŸºæ–¼ References.txt ä¸­çš„è³‡æ–™æ ¼å¼è¨­è¨ˆ
"""
import numpy as np
import pandas as pd
from typing import Dict, List, Optional
import logging

logger = logging.getLogger(__name__)


class IntradayStructureProcessor:
    """
    æ—¥å…§çµæ§‹ç‰¹å¾µè™•ç†å™¨
    
    å¾ 5åˆ†K è³‡æ–™èƒå– 5 å€‹æ—¥å…§çµæ§‹ä¿¡è™Ÿï¼š
    1. volatility: æ—¥å…§æ³¢å‹•åº¦
    2. vwap_deviation: VWAPåé›¢åº¦  
    3. volume_rhythm: æˆäº¤é‡ç¯€å¥
    4. shadow_ratio: ä¸Šä¸‹å½±æ¯”
    5. noise_ratio: å™ªéŸ³æ¯”
    """
    
    def __init__(self):
        self.feature_names = [
            'volatility',      # æ—¥å…§æ³¢å‹•åº¦
            'vwap_deviation',  # VWAPåé›¢åº¦
            'volume_rhythm',   # æˆäº¤é‡ç¯€å¥
            'shadow_ratio',    # ä¸Šä¸‹å½±æ¯”
            'noise_ratio'      # å™ªéŸ³æ¯”
        ]
        
        # é æœŸçš„ 5åˆ†K æ¬„ä½ (åŸºæ–¼ References.txt)
        self.expected_columns = ['open', 'high', 'low', 'close', 'volume']
    
    def process_daily_bars(self, minute_bars: pd.DataFrame) -> Dict[str, float]:
        """
        è™•ç†å–®æ—¥çš„5åˆ†Kè³‡æ–™ï¼Œèƒå–æ—¥å…§çµæ§‹ä¿¡è™Ÿ
        
        Args:
            minute_bars: å–®æ—¥çš„5åˆ†Kè³‡æ–™ (ç´„64æ ¹Kç·š)
                        åŒ…å«æ¬„ä½: open, high, low, close, volume
            
        Returns:
            Dict: 5å€‹æ—¥å…§çµæ§‹ç‰¹å¾µå€¼
        """
        # é©—è­‰è¼¸å…¥è³‡æ–™
        if not self._validate_input(minute_bars):
            return self._get_default_features()
        
        try:
            # 1. æ—¥å…§æ³¢å‹•åº¦
            volatility = self._calculate_volatility(minute_bars)
            
            # 2. VWAPåé›¢åº¦
            vwap_deviation = self._calculate_vwap_deviation(minute_bars)
            
            # 3. æˆäº¤é‡ç¯€å¥
            volume_rhythm = self._calculate_volume_rhythm(minute_bars)
            
            # 4. ä¸Šä¸‹å½±æ¯”
            shadow_ratio = self._calculate_shadow_ratio(minute_bars)
            
            # 5. å™ªéŸ³æ¯”
            noise_ratio = self._calculate_noise_ratio(minute_bars)
            
            features = {
                'volatility': volatility,
                'vwap_deviation': vwap_deviation,
                'volume_rhythm': volume_rhythm,
                'shadow_ratio': shadow_ratio,
                'noise_ratio': noise_ratio
            }
            
            # æª¢æŸ¥ä¸¦è™•ç†ç•°å¸¸å€¼
            features = self._handle_outliers(features)
            
            return features
            
        except Exception as e:
            logger.warning(f"æ—¥å…§çµæ§‹ç‰¹å¾µè¨ˆç®—å¤±æ•—: {e}")
            return self._get_default_features()
    
    def _validate_input(self, bars: pd.DataFrame) -> bool:
        """é©—è­‰è¼¸å…¥è³‡æ–™"""
        if bars is None or len(bars) == 0:
            return False
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        missing_cols = [col for col in self.expected_columns if col not in bars.columns]
        if missing_cols:
            logger.warning(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_cols}")
            return False
        
        # æª¢æŸ¥è³‡æ–™æœ‰æ•ˆæ€§
        if bars[self.expected_columns].isnull().all().any():
            logger.warning("å­˜åœ¨å…¨ç©ºçš„æ¬„ä½")
            return False
        
        return True
    
    def _get_default_features(self) -> Dict[str, float]:
        """ç²å–é è¨­ç‰¹å¾µå€¼"""
        return {name: 0.0 for name in self.feature_names}
    
    def _calculate_volatility(self, bars: pd.DataFrame) -> float:
        """
        è¨ˆç®—æ—¥å…§æ³¢å‹•åº¦
        
        æ–¹æ³•: (high - low) / close çš„æ—¥å…§æ¨™æº–å·®
        åæ˜ åƒ¹æ ¼åœ¨æ—¥å…§çš„æ³¢å‹•ç¨‹åº¦
        """
        if len(bars) == 0:
            return 0.0
        
        # é¿å…é™¤é›¶éŒ¯èª¤
        close_prices = bars['close'].replace(0, np.nan)
        if close_prices.isnull().all():
            return 0.0
        
        # è¨ˆç®—æ¯æ ¹Kç·šçš„æ³¢å‹•ç‡
        bar_volatility = (bars['high'] - bars['low']) / close_prices
        
        # ç§»é™¤ç•°å¸¸å€¼
        bar_volatility = bar_volatility.replace([np.inf, -np.inf], np.nan)
        bar_volatility = bar_volatility.dropna()
        
        if len(bar_volatility) == 0:
            return 0.0
        
        return float(bar_volatility.std())
    
    def _calculate_vwap_deviation(self, bars: pd.DataFrame) -> float:
        """
        è¨ˆç®—VWAPåé›¢åº¦
        
        æ–¹æ³•: (æ”¶ç›¤åƒ¹ - VWAP) / VWAP
        åæ˜ åƒ¹æ ¼ç›¸å°æ–¼æˆäº¤é‡åŠ æ¬Šå¹³å‡åƒ¹æ ¼çš„åé›¢ç¨‹åº¦
        """
        if len(bars) == 0:
            return 0.0
        
        # è¨ˆç®—VWAP
        total_volume = bars['volume'].sum()
        if total_volume == 0:
            return 0.0
        
        # ä½¿ç”¨å…¸å‹åƒ¹æ ¼è¨ˆç®—VWAP
        typical_price = (bars['high'] + bars['low'] + bars['close']) / 3
        vwap = (typical_price * bars['volume']).sum() / total_volume
        
        # è¨ˆç®—åé›¢åº¦
        final_close = bars['close'].iloc[-1]
        if vwap == 0:
            return 0.0
        
        deviation = (final_close - vwap) / vwap
        
        # é™åˆ¶åé›¢åº¦ç¯„åœ
        deviation = np.clip(deviation, -1.0, 1.0)
        
        return float(deviation)
    
    def _calculate_volume_rhythm(self, bars: pd.DataFrame) -> float:
        """
        è¨ˆç®—æˆäº¤é‡ç¯€å¥
        
        æ–¹æ³•: æˆäº¤é‡åˆ†ä½ˆçš„è®Šç•°ä¿‚æ•¸
        åæ˜ æˆäº¤é‡åœ¨æ—¥å…§çš„åˆ†ä½ˆå‡å‹»ç¨‹åº¦
        """
        if len(bars) == 0:
            return 0.0
        
        volumes = bars['volume']
        mean_volume = volumes.mean()
        
        if mean_volume == 0:
            return 0.0
        
        # è®Šç•°ä¿‚æ•¸ = æ¨™æº–å·® / å¹³å‡å€¼
        volume_cv = volumes.std() / mean_volume
        
        # é™åˆ¶è®Šç•°ä¿‚æ•¸ç¯„åœ
        volume_cv = np.clip(volume_cv, 0, 10.0)
        
        return float(volume_cv)
    
    def _calculate_shadow_ratio(self, bars: pd.DataFrame) -> float:
        """
        è¨ˆç®—ä¸Šä¸‹å½±æ¯”
        
        æ–¹æ³•: (ä¸Šå½±ç·š - ä¸‹å½±ç·š) / å¯¦é«” çš„å¹³å‡å€¼
        åæ˜ è²·è³£å£“åŠ›çš„ç›¸å°å¼·åº¦
        """
        if len(bars) == 0:
            return 0.0
        
        # è¨ˆç®—ä¸Šå½±ç·šå’Œä¸‹å½±ç·š
        upper_shadow = bars['high'] - np.maximum(bars['open'], bars['close'])
        lower_shadow = np.minimum(bars['open'], bars['close']) - bars['low']
        
        # è¨ˆç®—å¯¦é«”å¤§å°
        body_size = np.abs(bars['close'] - bars['open'])
        
        # é¿å…é™¤é›¶éŒ¯èª¤ï¼Œç‚ºå¯¦é«”å¤§å°æ·»åŠ å°çš„å¸¸æ•¸
        body_size_safe = body_size + 1e-8
        
        # è¨ˆç®—ä¸Šä¸‹å½±æ¯”
        shadow_ratio = (upper_shadow - lower_shadow) / body_size_safe
        
        # ç§»é™¤ç•°å¸¸å€¼
        shadow_ratio = shadow_ratio.replace([np.inf, -np.inf], np.nan)
        shadow_ratio = shadow_ratio.dropna()
        
        if len(shadow_ratio) == 0:
            return 0.0
        
        # é™åˆ¶ç¯„åœ
        mean_ratio = shadow_ratio.mean()
        mean_ratio = np.clip(mean_ratio, -10.0, 10.0)
        
        return float(mean_ratio)
    
    def _calculate_noise_ratio(self, bars: pd.DataFrame) -> float:
        """
        è¨ˆç®—å™ªéŸ³æ¯”
        
        æ–¹æ³•: ç¸½åƒ¹æ ¼è®Šå‹• / æ·¨åƒ¹æ ¼è®Šå‹•
        åæ˜ åƒ¹æ ¼è®Šå‹•ä¸­å™ªéŸ³çš„æ¯”ä¾‹
        """
        if len(bars) <= 1:
            return 0.0
        
        # è¨ˆç®—åƒ¹æ ¼è®Šå‹•
        price_changes = bars['close'].diff().abs()
        total_movement = price_changes.sum()
        
        # è¨ˆç®—æ·¨è®Šå‹•
        net_movement = abs(bars['close'].iloc[-1] - bars['close'].iloc[0])
        
        if net_movement == 0:
            # å¦‚æœæ²’æœ‰æ·¨è®Šå‹•ä½†æœ‰ç¸½è®Šå‹•ï¼Œèªªæ˜å…¨æ˜¯å™ªéŸ³
            return 10.0 if total_movement > 0 else 0.0
        
        noise_ratio = total_movement / net_movement
        
        # é™åˆ¶å™ªéŸ³æ¯”ç¯„åœ
        noise_ratio = np.clip(noise_ratio, 1.0, 20.0)
        
        return float(noise_ratio)
    
    def _handle_outliers(self, features: Dict[str, float]) -> Dict[str, float]:
        """è™•ç†ç•°å¸¸å€¼"""
        # å®šç¾©å„ç‰¹å¾µçš„åˆç†ç¯„åœ
        ranges = {
            'volatility': (0.0, 1.0),
            'vwap_deviation': (-1.0, 1.0),
            'volume_rhythm': (0.0, 10.0),
            'shadow_ratio': (-10.0, 10.0),
            'noise_ratio': (1.0, 20.0)
        }
        
        cleaned_features = {}
        for name, value in features.items():
            if name in ranges:
                min_val, max_val = ranges[name]
                cleaned_value = np.clip(value, min_val, max_val)
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ•ˆæ•¸å€¼
                if np.isnan(cleaned_value) or np.isinf(cleaned_value):
                    cleaned_value = 0.0
                
                cleaned_features[name] = float(cleaned_value)
            else:
                cleaned_features[name] = float(value) if not (np.isnan(value) or np.isinf(value)) else 0.0
        
        return cleaned_features
    
    def process_symbol_data(self, minute_data: pd.DataFrame) -> pd.DataFrame:
        """
        è™•ç†å¤šè‚¡ç¥¨å¤šæ—¥çš„5åˆ†Kè³‡æ–™ï¼ŒæŒ‰ symbol + date åˆ†çµ„
        
        Args:
            minute_data: åŒ…å« symbol, timestamp, OHLCV çš„5åˆ†Kè³‡æ–™
                        timestamp æ ¼å¼: '2020-03-02 09:00:00' (åŸºæ–¼ References.txt)
            
        Returns:
            pd.DataFrame: æ¯å€‹ (symbol, date) çµ„åˆçš„æ—¥å…§çµæ§‹ç‰¹å¾µ
        """
        if minute_data.empty:
            return pd.DataFrame()
        
        # é©—è­‰å¿…è¦æ¬„ä½
        required_columns = ['symbol', 'timestamp'] + self.expected_columns
        missing_cols = [col for col in required_columns if col not in minute_data.columns]
        if missing_cols:
            logger.error(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_cols}")
            return pd.DataFrame()
        
        # å¾ timestamp æå–æ—¥æœŸ
        minute_data = minute_data.copy()
        minute_data['date'] = pd.to_datetime(minute_data['timestamp']).dt.date
        
        # æŒ‰ symbol + date åˆ†çµ„è™•ç†
        results = []
        
        for (symbol, date), group_data in minute_data.groupby(['symbol', 'date']):
            # æŒ‰æ™‚é–“æ’åºç¢ºä¿æ­£ç¢ºçš„æ™‚é–“åºåˆ—
            group_data = group_data.sort_values('timestamp')
            
            # èƒå–æ—¥å…§çµæ§‹ç‰¹å¾µ
            features = self.process_daily_bars(group_data)
            
            # æ·»åŠ è­˜åˆ¥ä¿¡æ¯
            features['symbol'] = symbol
            features['date'] = date
            features['bar_count'] = len(group_data)  # è¨˜éŒ„å¯¦éš›Kç·šæ•¸é‡
            
            results.append(features)
        
        if not results:
            return pd.DataFrame()
        
        # è½‰æ›ç‚ºDataFrame
        result_df = pd.DataFrame(results)
        
        # é‡æ–°æ’åˆ—æ¬„ä½é †åº
        columns = ['symbol', 'date', 'bar_count'] + self.feature_names
        result_df = result_df[columns]
        
        return result_df
    
    def process_single_symbol_multiple_days(self, symbol_data: pd.DataFrame, 
                                          symbol: str) -> pd.DataFrame:
        """
        è™•ç†å–®ä¸€è‚¡ç¥¨å¤šæ—¥çš„5åˆ†Kè³‡æ–™
        
        Args:
            symbol_data: å–®ä¸€è‚¡ç¥¨çš„5åˆ†Kè³‡æ–™
            symbol: è‚¡ç¥¨ä»£ç¢¼
            
        Returns:
            pd.DataFrame: è©²è‚¡ç¥¨æ¯æ—¥çš„æ—¥å…§çµæ§‹ç‰¹å¾µ
        """
        if symbol_data.empty:
            return pd.DataFrame()
        
        # æ·»åŠ  symbol æ¬„ä½å¦‚æœä¸å­˜åœ¨
        if 'symbol' not in symbol_data.columns:
            symbol_data = symbol_data.copy()
            symbol_data['symbol'] = symbol
        
        return self.process_symbol_data(symbol_data)


def test_intraday_processor():
    """æ¸¬è©¦æ—¥å…§çµæ§‹ç‰¹å¾µè™•ç†å™¨"""
    print("=== æ¸¬è©¦æ—¥å…§çµæ§‹ç‰¹å¾µè™•ç†å™¨ ===")
    
    # å‰µå»ºæ¸¬è©¦è³‡æ–™ (æ¨¡æ“¬ References.txt çš„æ ¼å¼)
    np.random.seed(42)
    
    # æ¨¡æ“¬å¤šè‚¡ç¥¨å¤šæ—¥çš„5åˆ†Kè³‡æ–™
    symbols = ['2330', '2317']
    dates = ['2020-03-02', '2020-03-03']
    test_data = []
    
    for symbol in symbols:
        for date in dates:
            # æ¯æ—¥ç´„64æ ¹5åˆ†Kç·š (09:00-13:30)
            base_price = 100.0 if symbol == '2330' else 50.0
            
            # ç”Ÿæˆä¸€å¤©çš„æ™‚é–“æˆ³
            start_time = pd.Timestamp(f'{date} 09:00:00')
            times = [start_time + pd.Timedelta(minutes=5*i) for i in range(64)]
            
            for i, timestamp in enumerate(times):
                # æ¨¡æ“¬åƒ¹æ ¼éš¨æ©ŸéŠèµ°
                price_change = np.random.normal(0, 0.5)
                base_price += price_change
                
                # ç”ŸæˆOHLCV
                open_price = base_price
                high_price = open_price + abs(np.random.normal(0, 0.3))
                low_price = open_price - abs(np.random.normal(0, 0.3))
                close_price = open_price + np.random.normal(0, 0.2)
                volume = max(100, np.random.normal(1000, 300))
                
                test_data.append({
                    'symbol': symbol,
                    'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                    'open': open_price,
                    'high': high_price,
                    'low': low_price,
                    'close': close_price,
                    'volume': volume
                })
    
    test_df = pd.DataFrame(test_data)
    
    print(f"ğŸ“Š æ¸¬è©¦è³‡æ–™æ¦‚æ³:")
    print(f"   ç¸½è¨˜éŒ„æ•¸: {len(test_df)}")
    print(f"   è‚¡ç¥¨æ•¸: {test_df['symbol'].nunique()}")
    print(f"   æ—¥æœŸç¯„åœ: {test_df['timestamp'].min()} ~ {test_df['timestamp'].max()}")
    
    # æ¸¬è©¦è™•ç†å™¨
    processor = IntradayStructureProcessor()
    
    # 1. æ¸¬è©¦å–®æ—¥è™•ç†
    print(f"\n1ï¸âƒ£ æ¸¬è©¦å–®æ—¥è™•ç† (2330, 2020-03-02):")
    single_day_data = test_df[(test_df['symbol'] == '2330') & 
                             (test_df['timestamp'].str.startswith('2020-03-02'))]
    features = processor.process_daily_bars(single_day_data)
    
    for name, value in features.items():
        print(f"   {name}: {value:.6f}")
    
    # 2. æ¸¬è©¦å¤šè‚¡ç¥¨å¤šæ—¥è™•ç†
    print(f"\n2ï¸âƒ£ æ¸¬è©¦å¤šè‚¡ç¥¨å¤šæ—¥è™•ç†:")
    result_df = processor.process_symbol_data(test_df)
    
    print(f"   è™•ç†çµæœ:")
    print(f"   - ç¸½çµ„åˆæ•¸: {len(result_df)}")
    print(f"   - æ¬„ä½: {list(result_df.columns)}")
    
    print(f"\n   è©³ç´°çµæœ:")
    for _, row in result_df.iterrows():
        print(f"   {row['symbol']} {row['date']}: {row['bar_count']}æ ¹Kç·š")
        print(f"     volatility={row['volatility']:.4f}, vwap_deviation={row['vwap_deviation']:.4f}")
        print(f"     volume_rhythm={row['volume_rhythm']:.4f}, shadow_ratio={row['shadow_ratio']:.4f}")
        print(f"     noise_ratio={row['noise_ratio']:.4f}")
    
    # 3. æ¸¬è©¦å–®è‚¡ç¥¨è™•ç†
    print(f"\n3ï¸âƒ£ æ¸¬è©¦å–®è‚¡ç¥¨è™•ç† (2330):")
    symbol_2330_data = test_df[test_df['symbol'] == '2330']
    single_symbol_result = processor.process_single_symbol_multiple_days(symbol_2330_data, '2330')
    
    print(f"   2330 è™•ç†çµæœ: {len(single_symbol_result)} å€‹äº¤æ˜“æ—¥")
    for _, row in single_symbol_result.iterrows():
        print(f"     {row['date']}: volatility={row['volatility']:.4f}")
    
    print("\nâœ… æ—¥å…§çµæ§‹ç‰¹å¾µè™•ç†å™¨æ¸¬è©¦å®Œæˆ")
    
    return result_df


if __name__ == "__main__":
    test_intraday_processor()
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è³‡æ–™è¼‰å…¥å™¨ä¿®å¾©æ¸¬è©¦ - é©—è­‰ç´¢å¼•è¶Šç•Œå•é¡Œä¿®å¾©
"""
import sys
import os
from pathlib import Path
import traceback
from datetime import datetime
import numpy as np
import torch

# å¼·åˆ¶UTF-8è¼¸å‡º
sys.stdout.reconfigure(encoding='utf-8')

# æ·»åŠ è·¯å¾‘
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent / "models"))
sys.path.append(str(Path(__file__).parent / "data_pipeline"))
sys.path.append(str(Path(__file__).parent / "market_data_collector"))

def print_status(task, status, details=""):
    """çµ±ä¸€çš„ç‹€æ…‹è¼¸å‡ºæ ¼å¼"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    status_icon = "âœ…" if status == "SUCCESS" else "âŒ" if status == "FAILED" else "ğŸ”„"
    print(f"[{timestamp}] {status_icon} {task}: {status}")
    if details:
        print(f"    è©³æƒ…: {details}")

def test_dataloader_fix():
    """æ¸¬è©¦è³‡æ–™è¼‰å…¥å™¨ä¿®å¾©"""
    print("ğŸ§ª æ¸¬è©¦è³‡æ–™è¼‰å…¥å™¨ç´¢å¼•è¶Šç•Œä¿®å¾©")
    print("="*60)
    
    try:
        from models.config.training_config import TrainingConfig
        from models.data_loader import TSEDataLoader, DataConfig
        from data_pipeline.features import FeatureEngine
        
        # è¨“ç·´é…ç½®
        print("âš™ï¸ è¨­ç½®æ¸¬è©¦é…ç½®...")
        training_config = TrainingConfig()
        
        # æ¸¬è©¦åƒæ•¸
        test_symbols = ['2330', '2317']  # åªç”¨2æ”¯è‚¡ç¥¨
        batch_size = 2
        
        print(f"   æ¸¬è©¦è‚¡ç¥¨: {test_symbols}")
        print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"   æœŸæœ›ç‰¹å¾µç¶­åº¦: {training_config.total_features}")
        
        # æº–å‚™è³‡æ–™
        print("ğŸ“Š æº–å‚™æ¸¬è©¦è³‡æ–™...")
        feature_engine = FeatureEngine(symbols=test_symbols)
        
        # è™•ç†ç‰¹å¾µ (ä½¿ç”¨æ›´å¤§çš„æ—¥æœŸç¯„åœç¢ºä¿æœ‰è¶³å¤ è³‡æ–™)
        features_dict = feature_engine.process_multiple_symbols(
            symbols=test_symbols,
            start_date='2023-01-01',  # æ“´å¤§æ—¥æœŸç¯„åœ
            end_date='2023-12-31',    
            normalize=True
        )
        
        if not features_dict:
            raise ValueError("ç„¡æ³•ç²å–æ¸¬è©¦è³‡æ–™")
        
        print(f"   æˆåŠŸè™•ç† {len(features_dict)} æ”¯è‚¡ç¥¨çš„ç‰¹å¾µ")
        
        # å‰µå»ºè³‡æ–™è¼‰å…¥å™¨ (ä½¿ç”¨æ›´å¤§çš„æ—¥æœŸç¯„åœ)
        data_config = DataConfig(
            symbols=test_symbols,
            train_start_date='2023-01-01',
            train_end_date='2023-10-31',
            val_start_date='2023-11-01',
            val_end_date='2023-12-31',
            sequence_length=16,
            batch_size=batch_size,
            num_workers=0
        )
        
        data_loader = TSEDataLoader(data_config)
        data_loader.features_dict = features_dict
        
        train_loader, val_loader, _ = data_loader.get_dataloaders()
        
        print(f"   è¨“ç·´æ‰¹æ¬¡: {len(train_loader)}")
        print(f"   é©—è­‰æ‰¹æ¬¡: {len(val_loader)}")
        
        if len(train_loader) == 0:
            print("âš ï¸ è¨“ç·´è³‡æ–™è¼‰å…¥å™¨ç‚ºç©ºï¼Œä½†é€™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼ˆè³‡æ–™ç¯„åœå°ï¼‰")
            return True
        
        # æ¸¬è©¦è³‡æ–™è¼‰å…¥
        print("ğŸ” æ¸¬è©¦è³‡æ–™è¼‰å…¥...")
        
        batch_count = 0
        for batch_idx, batch in enumerate(train_loader):
            if batch_idx >= 3:  # åªæ¸¬è©¦å‰3å€‹æ‰¹æ¬¡
                break
            
            batch_count += 1
            observation = batch['observation']
            labels = batch['labels']
            
            print(f"   æ‰¹æ¬¡ {batch_idx + 1}:")
            print(f"     price_frame: {observation['price_frame'].shape}")
            print(f"     fundamental: {observation['fundamental'].shape}")
            print(f"     account: {observation['account'].shape}")
            print(f"     labels: {labels.shape}")
            
            # é©—è­‰å½¢ç‹€
            expected_price_shape = (batch_size, len(test_symbols), 16, training_config.other_features)
            expected_fundamental_shape = (batch_size, training_config.fundamental_features)
            expected_account_shape = (batch_size, 4)  # å¸³æˆ¶ç‰¹å¾µä»ç„¶æ˜¯4ç¶­
            
            if observation['price_frame'].shape != expected_price_shape:
                print(f"     âš ï¸ price_frameå½¢ç‹€ä¸åŒ¹é…: æœŸæœ›{expected_price_shape}, å¯¦éš›{observation['price_frame'].shape}")
            
            if observation['fundamental'].shape != expected_fundamental_shape:
                print(f"     âš ï¸ fundamentalå½¢ç‹€ä¸åŒ¹é…: æœŸæœ›{expected_fundamental_shape}, å¯¦éš›{observation['fundamental'].shape}")
            
            if observation['account'].shape != expected_account_shape:
                print(f"     âš ï¸ accountå½¢ç‹€ä¸åŒ¹é…: æœŸæœ›{expected_account_shape}, å¯¦éš›{observation['account'].shape}")
            
            # æª¢æŸ¥æ•¸å€¼
            if torch.isnan(observation['price_frame']).any():
                print(f"     âš ï¸ price_frameåŒ…å«NaNå€¼")
            
            if torch.isnan(observation['fundamental']).any():
                print(f"     âš ï¸ fundamentalåŒ…å«NaNå€¼")
            
            if torch.isnan(observation['account']).any():
                print(f"     âš ï¸ accountåŒ…å«NaNå€¼")
        
        print(f"âœ… æˆåŠŸè¼‰å…¥ {batch_count} å€‹æ‰¹æ¬¡ï¼Œç„¡ç´¢å¼•è¶Šç•ŒéŒ¯èª¤")
        
        # æ¸¬è©¦é©—è­‰é›†
        print("ğŸ” æ¸¬è©¦é©—è­‰é›†è¼‰å…¥...")
        val_batch_count = 0
        for batch_idx, batch in enumerate(val_loader):
            if batch_idx >= 2:  # åªæ¸¬è©¦å‰2å€‹æ‰¹æ¬¡
                break
            val_batch_count += 1
        
        print(f"âœ… æˆåŠŸè¼‰å…¥ {val_batch_count} å€‹é©—è­‰æ‰¹æ¬¡")
        
        print_status("è³‡æ–™è¼‰å…¥å™¨ä¿®å¾©æ¸¬è©¦", "SUCCESS", f"æˆåŠŸè¼‰å…¥ {batch_count} å€‹è¨“ç·´æ‰¹æ¬¡å’Œ {val_batch_count} å€‹é©—è­‰æ‰¹æ¬¡")
        return True
        
    except Exception as e:
        print_status("è³‡æ–™è¼‰å…¥å™¨ä¿®å¾©æ¸¬è©¦", "FAILED", str(e))
        traceback.print_exc()
        return False

def test_model_integration():
    """æ¸¬è©¦æ¨¡å‹æ•´åˆ"""
    print("\nğŸ§ª æ¸¬è©¦æ¨¡å‹æ•´åˆ")
    print("="*60)
    
    try:
        from models.model_architecture import ModelConfig, TSEAlphaModel
        from models.config.training_config import TrainingConfig
        
        training_config = TrainingConfig()
        test_symbols = ['2330', '2317']
        
        print("ğŸ¤– å‰µå»ºæ¸¬è©¦æ¨¡å‹...")
        model_config = ModelConfig(
            price_frame_shape=(len(test_symbols), 16, training_config.other_features),
            fundamental_dim=training_config.fundamental_features,
            account_dim=4,  # å¼·åˆ¶ä½¿ç”¨4ç¶­å¸³æˆ¶ç‰¹å¾µ
            hidden_dim=64,
            num_layers=2
        )
        
        model = TSEAlphaModel(model_config)
        
        print(f"   æ¨¡å‹é…ç½®: {model_config.price_frame_shape}")
        print(f"   åŸºæœ¬é¢ç¶­åº¦: {model_config.fundamental_dim}")
        print(f"   å¸³æˆ¶ç¶­åº¦: {model_config.account_dim}")
        
        # å‰µå»ºæ¸¬è©¦è¼¸å…¥
        batch_size = 2
        test_observation = {
            'price_frame': torch.randn(batch_size, len(test_symbols), 16, training_config.other_features),
            'fundamental': torch.randn(batch_size, training_config.fundamental_features),
            'account': torch.randn(batch_size, 4)
        }
        
        print("ğŸ”„ æ¸¬è©¦å‰å‘å‚³æ’­...")
        model.eval()
        with torch.no_grad():
            outputs = model(test_observation)
        
        print(f"   è¼¸å‡ºå½¢ç‹€:")
        for key, value in outputs.items():
            print(f"     {key}: {value.shape}")
        
        print_status("æ¨¡å‹æ•´åˆæ¸¬è©¦", "SUCCESS", "æ¨¡å‹å‰å‘å‚³æ’­æ­£å¸¸")
        return True
        
    except Exception as e:
        print_status("æ¨¡å‹æ•´åˆæ¸¬è©¦", "FAILED", str(e))
        traceback.print_exc()
        return False

def run_dataloader_fix_test():
    """åŸ·è¡Œè³‡æ–™è¼‰å…¥å™¨ä¿®å¾©æ¸¬è©¦"""
    print("ğŸš€ é–‹å§‹è³‡æ–™è¼‰å…¥å™¨ä¿®å¾©æ¸¬è©¦")
    print("="*80)
    
    start_time = datetime.now()
    
    # åŸ·è¡Œæ¸¬è©¦
    success_1 = test_dataloader_fix()
    success_2 = test_model_integration()
    
    # ç¸½çµ
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    results = {
        "è³‡æ–™è¼‰å…¥å™¨ä¿®å¾©": success_1,
        "æ¨¡å‹æ•´åˆ": success_2
    }
    
    print("\n" + "="*80)
    print("ğŸ“‹ æ¸¬è©¦ç¸½çµ")
    print("="*80)
    
    success_count = sum(1 for success in results.values() if success)
    total_count = len(results)
    
    for test_name, success in results.items():
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±æ•—"
        print(f"   {test_name}: {status}")
    
    print(f"\nğŸ“Š ç¸½é«”çµæœ: {success_count}/{total_count} æ¸¬è©¦æˆåŠŸ")
    print(f"â±ï¸ åŸ·è¡Œæ™‚é–“: {duration:.1f} ç§’")
    
    if success_count == total_count:
        print("ğŸ‰ è³‡æ–™è¼‰å…¥å™¨ä¿®å¾©æ¸¬è©¦ - å…¨éƒ¨é€šéï¼")
        print("âœ… ç´¢å¼•è¶Šç•Œå•é¡Œå·²ä¿®å¾©ï¼Œå¯ä»¥é‡æ–°åŸ·è¡Œéšæ®µ4æ¸¬è©¦")
        return True
    else:
        print("âš ï¸ è³‡æ–™è¼‰å…¥å™¨ä¿®å¾©æ¸¬è©¦ - éƒ¨åˆ†å¤±æ•—")
        print("âŒ éœ€è¦é€²ä¸€æ­¥èª¿è©¦")
        return False

if __name__ == "__main__":
    try:
        success = run_dataloader_fix_test()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ¶ä¸­æ–·æ¸¬è©¦")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æœªé æœŸçš„éŒ¯èª¤: {e}")
        traceback.print_exc()
        sys.exit(1)